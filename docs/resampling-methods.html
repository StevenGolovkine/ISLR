<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Resampling Methods | An Introduction to Statistical Learning</title>
  <meta name="description" content="This book aims to provide my results to the different exercises of An Introduction to Statistical Learning, with Application in R, by James, Witten, Hastie and Tibshirani." />
  <meta name="generator" content="bookdown 0.14 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Resampling Methods | An Introduction to Statistical Learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book aims to provide my results to the different exercises of An Introduction to Statistical Learning, with Application in R, by James, Witten, Hastie and Tibshirani." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Resampling Methods | An Introduction to Statistical Learning" />
  
  <meta name="twitter:description" content="This book aims to provide my results to the different exercises of An Introduction to Statistical Learning, with Application in R, by James, Witten, Hastie and Tibshirani." />
  

<meta name="author" content="Steven Golovkine" />


<meta name="date" content="2019-11-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="classification.html"/>
<link rel="next" href="linear-model-selection-and-regularization.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Statistical Learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="overview.html"><a href="overview.html"><i class="fa fa-check"></i><b>2</b> An Overview of Statistical Learning</a><ul>
<li class="chapter" data-level="2.1" data-path="overview.html"><a href="overview.html#conceptual-exercises"><i class="fa fa-check"></i><b>2.1</b> Conceptual Exercises</a><ul>
<li class="chapter" data-level="2.1.1" data-path="overview.html"><a href="overview.html#exercise-1."><i class="fa fa-check"></i><b>2.1.1</b> Exercise 1.</a></li>
<li class="chapter" data-level="2.1.2" data-path="overview.html"><a href="overview.html#exercise-2."><i class="fa fa-check"></i><b>2.1.2</b> Exercise 2.</a></li>
<li class="chapter" data-level="2.1.3" data-path="overview.html"><a href="overview.html#exercise-3."><i class="fa fa-check"></i><b>2.1.3</b> Exercise 3.</a></li>
<li class="chapter" data-level="2.1.4" data-path="overview.html"><a href="overview.html#exercise-4."><i class="fa fa-check"></i><b>2.1.4</b> Exercise 4.</a></li>
<li class="chapter" data-level="2.1.5" data-path="overview.html"><a href="overview.html#exercise-5."><i class="fa fa-check"></i><b>2.1.5</b> Exercise 5.</a></li>
<li class="chapter" data-level="2.1.6" data-path="overview.html"><a href="overview.html#exercise-6."><i class="fa fa-check"></i><b>2.1.6</b> Exercise 6.</a></li>
<li class="chapter" data-level="2.1.7" data-path="overview.html"><a href="overview.html#exercise-7."><i class="fa fa-check"></i><b>2.1.7</b> Exercise 7.</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="overview.html"><a href="overview.html#applied-exercises"><i class="fa fa-check"></i><b>2.2</b> Applied Exercises</a><ul>
<li class="chapter" data-level="2.2.1" data-path="overview.html"><a href="overview.html#exercise-8."><i class="fa fa-check"></i><b>2.2.1</b> Exercise 8.</a></li>
<li class="chapter" data-level="2.2.2" data-path="overview.html"><a href="overview.html#exercise-9."><i class="fa fa-check"></i><b>2.2.2</b> Exercise 9.</a></li>
<li class="chapter" data-level="2.2.3" data-path="overview.html"><a href="overview.html#exercise-10."><i class="fa fa-check"></i><b>2.2.3</b> Exercise 10.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>3</b> Linear Regression</a><ul>
<li class="chapter" data-level="3.1" data-path="linear-regression.html"><a href="linear-regression.html#conceptual-exercises-1"><i class="fa fa-check"></i><b>3.1</b> Conceptual Exercises</a><ul>
<li class="chapter" data-level="3.1.1" data-path="linear-regression.html"><a href="linear-regression.html#exercise-1.-1"><i class="fa fa-check"></i><b>3.1.1</b> Exercise 1.</a></li>
<li class="chapter" data-level="3.1.2" data-path="linear-regression.html"><a href="linear-regression.html#exercise-2.-1"><i class="fa fa-check"></i><b>3.1.2</b> Exercise 2.</a></li>
<li class="chapter" data-level="3.1.3" data-path="linear-regression.html"><a href="linear-regression.html#exercise-3.-1"><i class="fa fa-check"></i><b>3.1.3</b> Exercise 3.</a></li>
<li class="chapter" data-level="3.1.4" data-path="linear-regression.html"><a href="linear-regression.html#exercise-4.-1"><i class="fa fa-check"></i><b>3.1.4</b> Exercise 4.</a></li>
<li class="chapter" data-level="3.1.5" data-path="linear-regression.html"><a href="linear-regression.html#exercise-5.-1"><i class="fa fa-check"></i><b>3.1.5</b> Exercise 5.</a></li>
<li class="chapter" data-level="3.1.6" data-path="linear-regression.html"><a href="linear-regression.html#exercise-6.-1"><i class="fa fa-check"></i><b>3.1.6</b> Exercise 6.</a></li>
<li class="chapter" data-level="3.1.7" data-path="linear-regression.html"><a href="linear-regression.html#exercise-7.-1"><i class="fa fa-check"></i><b>3.1.7</b> Exercise 7.</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="linear-regression.html"><a href="linear-regression.html#applied-exercises-1"><i class="fa fa-check"></i><b>3.2</b> Applied Exercises</a><ul>
<li class="chapter" data-level="3.2.1" data-path="linear-regression.html"><a href="linear-regression.html#exercise-8.-1"><i class="fa fa-check"></i><b>3.2.1</b> Exercise 8.</a></li>
<li class="chapter" data-level="3.2.2" data-path="linear-regression.html"><a href="linear-regression.html#exercise-9.-1"><i class="fa fa-check"></i><b>3.2.2</b> Exercise 9.</a></li>
<li class="chapter" data-level="3.2.3" data-path="linear-regression.html"><a href="linear-regression.html#exercise-10.-1"><i class="fa fa-check"></i><b>3.2.3</b> Exercise 10.</a></li>
<li class="chapter" data-level="3.2.4" data-path="linear-regression.html"><a href="linear-regression.html#exercise-11."><i class="fa fa-check"></i><b>3.2.4</b> Exercise 11.</a></li>
<li class="chapter" data-level="3.2.5" data-path="linear-regression.html"><a href="linear-regression.html#exercise-12."><i class="fa fa-check"></i><b>3.2.5</b> Exercise 12.</a></li>
<li class="chapter" data-level="3.2.6" data-path="linear-regression.html"><a href="linear-regression.html#exercise-13."><i class="fa fa-check"></i><b>3.2.6</b> Exercise 13.</a></li>
<li class="chapter" data-level="3.2.7" data-path="linear-regression.html"><a href="linear-regression.html#exercise-14."><i class="fa fa-check"></i><b>3.2.7</b> Exercise 14.</a></li>
<li class="chapter" data-level="3.2.8" data-path="linear-regression.html"><a href="linear-regression.html#exercise-15."><i class="fa fa-check"></i><b>3.2.8</b> Exercise 15.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>4</b> Classification</a><ul>
<li class="chapter" data-level="4.1" data-path="classification.html"><a href="classification.html#conceptual-exercises-2"><i class="fa fa-check"></i><b>4.1</b> Conceptual Exercises</a><ul>
<li class="chapter" data-level="4.1.1" data-path="classification.html"><a href="classification.html#exercise-1.-2"><i class="fa fa-check"></i><b>4.1.1</b> Exercise 1.</a></li>
<li class="chapter" data-level="4.1.2" data-path="classification.html"><a href="classification.html#exercise-2.-2"><i class="fa fa-check"></i><b>4.1.2</b> Exercise 2.</a></li>
<li class="chapter" data-level="4.1.3" data-path="classification.html"><a href="classification.html#exercise-3.-2"><i class="fa fa-check"></i><b>4.1.3</b> Exercise 3.</a></li>
<li class="chapter" data-level="4.1.4" data-path="classification.html"><a href="classification.html#exercise-4.-2"><i class="fa fa-check"></i><b>4.1.4</b> Exercise 4.</a></li>
<li class="chapter" data-level="4.1.5" data-path="classification.html"><a href="classification.html#exercise-5.-2"><i class="fa fa-check"></i><b>4.1.5</b> Exercise 5.</a></li>
<li class="chapter" data-level="4.1.6" data-path="classification.html"><a href="classification.html#exercise-6.-2"><i class="fa fa-check"></i><b>4.1.6</b> Exercise 6.</a></li>
<li class="chapter" data-level="4.1.7" data-path="classification.html"><a href="classification.html#exercise-7.-2"><i class="fa fa-check"></i><b>4.1.7</b> Exercise 7.</a></li>
<li class="chapter" data-level="4.1.8" data-path="classification.html"><a href="classification.html#exercise-8.-2"><i class="fa fa-check"></i><b>4.1.8</b> Exercise 8.</a></li>
<li class="chapter" data-level="4.1.9" data-path="classification.html"><a href="classification.html#exercise-9.-2"><i class="fa fa-check"></i><b>4.1.9</b> Exercise 9.</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="classification.html"><a href="classification.html#applied-exercises-2"><i class="fa fa-check"></i><b>4.2</b> Applied Exercises</a><ul>
<li class="chapter" data-level="4.2.1" data-path="classification.html"><a href="classification.html#exercise-10.-2"><i class="fa fa-check"></i><b>4.2.1</b> Exercise 10.</a></li>
<li class="chapter" data-level="4.2.2" data-path="classification.html"><a href="classification.html#exercise-11.-1"><i class="fa fa-check"></i><b>4.2.2</b> Exercise 11.</a></li>
<li class="chapter" data-level="4.2.3" data-path="classification.html"><a href="classification.html#exercise-12.-1"><i class="fa fa-check"></i><b>4.2.3</b> Exercise 12.</a></li>
<li class="chapter" data-level="4.2.4" data-path="classification.html"><a href="classification.html#exercise-13.-1"><i class="fa fa-check"></i><b>4.2.4</b> Exercise 13.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="resampling-methods.html"><a href="resampling-methods.html"><i class="fa fa-check"></i><b>5</b> Resampling Methods</a><ul>
<li class="chapter" data-level="5.1" data-path="resampling-methods.html"><a href="resampling-methods.html#conceptual-exercises-3"><i class="fa fa-check"></i><b>5.1</b> Conceptual Exercises</a><ul>
<li class="chapter" data-level="5.1.1" data-path="resampling-methods.html"><a href="resampling-methods.html#exercise-1.-3"><i class="fa fa-check"></i><b>5.1.1</b> Exercise 1.</a></li>
<li class="chapter" data-level="5.1.2" data-path="resampling-methods.html"><a href="resampling-methods.html#exercise-2.-3"><i class="fa fa-check"></i><b>5.1.2</b> Exercise 2.</a></li>
<li class="chapter" data-level="5.1.3" data-path="resampling-methods.html"><a href="resampling-methods.html#exercise-3.-3"><i class="fa fa-check"></i><b>5.1.3</b> Exercise 3.</a></li>
<li class="chapter" data-level="5.1.4" data-path="resampling-methods.html"><a href="resampling-methods.html#exercise-4.-3"><i class="fa fa-check"></i><b>5.1.4</b> Exercise 4.</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="resampling-methods.html"><a href="resampling-methods.html#applied-exercises-3"><i class="fa fa-check"></i><b>5.2</b> Applied Exercises</a><ul>
<li class="chapter" data-level="5.2.1" data-path="resampling-methods.html"><a href="resampling-methods.html#exercise-5.-3"><i class="fa fa-check"></i><b>5.2.1</b> Exercise 5.</a></li>
<li class="chapter" data-level="5.2.2" data-path="resampling-methods.html"><a href="resampling-methods.html#exercise-6.-3"><i class="fa fa-check"></i><b>5.2.2</b> Exercise 6.</a></li>
<li class="chapter" data-level="5.2.3" data-path="resampling-methods.html"><a href="resampling-methods.html#exercise-7.-3"><i class="fa fa-check"></i><b>5.2.3</b> Exercise 7.</a></li>
<li class="chapter" data-level="5.2.4" data-path="resampling-methods.html"><a href="resampling-methods.html#exercise-8.-3"><i class="fa fa-check"></i><b>5.2.4</b> Exercise 8.</a></li>
<li class="chapter" data-level="5.2.5" data-path="resampling-methods.html"><a href="resampling-methods.html#exercise-9.-3"><i class="fa fa-check"></i><b>5.2.5</b> Exercise 9.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html"><i class="fa fa-check"></i><b>6</b> Linear Model Selection and Regularization</a><ul>
<li class="chapter" data-level="6.1" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#conceptual-exercises-4"><i class="fa fa-check"></i><b>6.1</b> Conceptual Exercises</a><ul>
<li class="chapter" data-level="6.1.1" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#exercise-1.-4"><i class="fa fa-check"></i><b>6.1.1</b> Exercise 1.</a></li>
<li class="chapter" data-level="6.1.2" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#exercise-2.-4"><i class="fa fa-check"></i><b>6.1.2</b> Exercise 2.</a></li>
<li class="chapter" data-level="6.1.3" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#exercise-3.-4"><i class="fa fa-check"></i><b>6.1.3</b> Exercise 3.</a></li>
<li class="chapter" data-level="6.1.4" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#exercise-4.-4"><i class="fa fa-check"></i><b>6.1.4</b> Exercise 4.</a></li>
<li class="chapter" data-level="6.1.5" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#exercise-5.-4"><i class="fa fa-check"></i><b>6.1.5</b> Exercise 5.</a></li>
<li class="chapter" data-level="6.1.6" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#exercise-6.-4"><i class="fa fa-check"></i><b>6.1.6</b> Exercise 6.</a></li>
<li class="chapter" data-level="6.1.7" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#exercise-7.-4"><i class="fa fa-check"></i><b>6.1.7</b> Exercise 7.</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#applied-exercises-4"><i class="fa fa-check"></i><b>6.2</b> Applied Exercises</a><ul>
<li class="chapter" data-level="6.2.1" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#exercise-8.-4"><i class="fa fa-check"></i><b>6.2.1</b> Exercise 8.</a></li>
<li class="chapter" data-level="6.2.2" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#exercise-9.-4"><i class="fa fa-check"></i><b>6.2.2</b> Exercise 9.</a></li>
<li class="chapter" data-level="6.2.3" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#exercise-10.-3"><i class="fa fa-check"></i><b>6.2.3</b> Exercise 10.</a></li>
<li class="chapter" data-level="6.2.4" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#exercise-11.-2"><i class="fa fa-check"></i><b>6.2.4</b> Exercise 11.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Statistical Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="resampling-methods" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> Resampling Methods</h1>
<div id="conceptual-exercises-3" class="section level2">
<h2><span class="header-section-number">5.1</span> Conceptual Exercises</h2>
<div id="exercise-1.-3" class="section level3">
<h3><span class="header-section-number">5.1.1</span> Exercise 1.</h3>
<p>Proof that <span class="math inline">\(\alpha = \frac{\sigma_Y^2 - \sigma_{X,Y}}{\sigma_X^2 + \sigma_Y^2 - 2\sigma_{X,Y}}\)</span> minimize <span class="math inline">\(\text{Var}(\alpha X + (1 - \alpha)Y)\)</span>.</p>
<p>Using properties of the variance, we found that:</p>
<p><span class="math display">\[\text{Var}(\alpha X + (1 - \alpha)Y) = \alpha^2\sigma_X^2 + (1 - \alpha)^2\sigma_Y^2 + 2\alpha(1 - \alpha)\sigma_{X,Y}.\]</span></p>
<p>As we seek to minimize this quantity with respect to <span class="math inline">\(\alpha\)</span>, we have to set the derivative with respect to <span class="math inline">\(\alpha\)</span> equal to <span class="math inline">\(0\)</span>.</p>
<p><span class="math display">\[\begin{align}
\frac{d\text{Var}(\alpha X + (1 - \alpha)Y)}{d\alpha} = 0 &amp;\Longleftrightarrow 2\alpha\sigma_X^2 + 2(1 - \alpha)\sigma_Y^2 + 2(1 - 2\alpha)\sigma_{X,Y} = 0 \\
&amp;\Longleftrightarrow \left(\sigma_X^2 + \sigma_Y^2 - 2\sigma_{X,Y}\right)\alpha = \sigma_Y^2 - \sigma_{X,Y} \\
&amp;\Longleftrightarrow \alpha = \frac{\sigma_Y^2 - \sigma_{X,Y}}{\sigma_X^2 + \sigma_Y^2 - 2\sigma_{X,Y}}
\end{align}\]</span></p>
</div>
<div id="exercise-2.-3" class="section level3">
<h3><span class="header-section-number">5.1.2</span> Exercise 2.</h3>
<p>Suppose that we obtain a bootstrap sample from a set of <span class="math inline">\(n\)</span> observations.</p>
<ul>
<li><em>Question (a)</em></li>
</ul>
<p>We draw one observation from a set of <span class="math inline">\(n\)</span> observations. So, the probability of getting a particular observation <span class="math inline">\(j\)</span> is <span class="math inline">\(1/n\)</span>.</p>
<p><span class="math display">\[\mathbb{P}(X_j \neq S^{(1)}) = 1 - \mathbb{P}(X_j = S^{(1)}) = 1 - \frac{1}{n}, \quad\text{where}~ S^{(1)} ~\text{is the first element of the sample.}\]</span></p>
<ul>
<li><em>Question (b)</em></li>
</ul>
<p>The bootstrap is performed <strong>wih replacement</strong>. So, the probability of getting a ârticular observation is <span class="math inline">\(1/n\)</span> at each drawing.</p>
<p><span class="math display">\[\mathbb{P}(X_j \neq S^{(2)}) = 1 - \mathbb{P}(X_j = S^{(2)}) = 1 - \frac{1}{n}, \quad\text{where}~ S^{(2)} ~\text{is the first element of the sample.}\]</span></p>
<ul>
<li><em>Question (c)</em></li>
</ul>
<p><span class="math display">\[\begin{align}
\mathbb{P}(X_j \notin S) &amp;= \mathbb{P}(X_j \neq S^{(1)}, \dots, X_j \neq S^{(n)}) \\
  &amp;= \mathbb{P}(X_j \neq S^{(1)}) \times \dots \times \mathbb{P}(X_j \neq S^{(n)}) \\
  &amp;= \left(1 -  \mathbb{P}(X_j = S^{(1)})\right) \times \dots \times \left(1 -  \mathbb{P}(X_j = S^{(n)})\right) \\
  &amp;= \left(1 - \frac{1}{n}\right)^n
\end{align}\]</span></p>
<ul>
<li><em>Question (d)</em></li>
</ul>
<p><span class="math display">\[\begin{align}
\mathbb{P}(X_j \in S) &amp;= \mathbb{P}(X_j \notin S)\\
  &amp;= 1 - \left(1 - \frac{1}{5}\right)^5 \\
  &amp;= 0.672
\end{align}\]</span></p>
<ul>
<li><em>Question (e)</em></li>
</ul>
<p><span class="math display">\[\begin{align}
\mathbb{P}(X_j \in S) &amp;= \mathbb{P}(X_j \notin S)\\
  &amp;= 1 - \left(1 - \frac{1}{100}\right)^{100} \\
  &amp;= 0.634
\end{align}\]</span></p>
<ul>
<li><em>Question (f)</em></li>
</ul>
<p><span class="math display">\[\begin{align}
\mathbb{P}(X_j \in S) &amp;= \mathbb{P}(X_j \notin S)\\
  &amp;= 1 - \left(1 - \frac{1}{10000}\right)^{10000} \\
  &amp;= 0.632
\end{align}\]</span></p>
<ul>
<li><em>Question (g)</em></li>
</ul>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="resampling-methods.html#cb69-1"></a>prob &lt;-<span class="st"> </span><span class="cf">function</span>(n) <span class="kw">return</span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>n))<span class="op">**</span>n)</span>
<span id="cb69-2"><a href="resampling-methods.html#cb69-2"></a>df &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">n =</span> <span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">1000</span>, <span class="dt">by =</span> <span class="dv">1</span>), <span class="dt">p =</span> <span class="kw">prob</span>(n))</span></code></pre></div>
<center>
<div class="figure" style="text-align: center"><span id="fig:ex2g"></span>
<img src="04-resampling_files/figure-html/ex2g-1.png" alt="Probability that a particular observation belongs to the bootstrap sample." width="480" />
<p class="caption">
Figure 5.1: Probability that a particular observation belongs to the bootstrap sample.
</p>
</div>
</center>
<p>We observe that the probability that the <span class="math inline">\(j\)</span>th observation is in the bootstrap samples seems to convergence until <span class="math inline">\(0.63\)</span>.</p>
<ul>
<li><em>Question (h)</em></li>
</ul>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="resampling-methods.html#cb70-1"></a>store &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="dv">1000</span>)</span>
<span id="cb70-2"><a href="resampling-methods.html#cb70-2"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>) store[i] &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">100</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>) <span class="op">==</span><span class="st"> </span><span class="dv">4</span>) <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span></span></code></pre></div>
<p>This piece of code repeatedly create bootstrap samples, and each time we record whether or not the fourth observation is contained in the bootstrap sample. In mean, we found that the fourth observation is contain in 63% of the samples. So, we retrieve the observation that gave at the previous question.</p>
<p>Mathematically, we can be prove like that:
<span class="math display">\[\begin{align}
1 - \left(1 - \frac{1}{n}\right)^n &amp;= 1 - \exp\left(n\ln\left(1 - \frac{1}{n}\right)\right) \\
&amp;\underset{n \rightarrow \infty}{=} 1 - \exp\left(n\left(-\frac{1}{n} + o\left(\frac{1}{n}\right)\right)\right) \\ 
&amp;\underset{n \rightarrow \infty}{\longrightarrow} 1 - \exp(-1)) \approx 0.63
\end{align}\]</span></p>
</div>
<div id="exercise-3.-3" class="section level3">
<h3><span class="header-section-number">5.1.3</span> Exercise 3.</h3>
<ul>
<li><em>Question (a)</em></li>
</ul>
<p>From page 181 of <em>Introduction to Statistical learning with R</em>:</p>
<ul>
<li>Step 1: Randomly divide the set of observation in <span class="math inline">\(k\)</span> groups;
<ul>
<li>Step 2: Fit the method on <span class="math inline">\(k-1\)</span> groups;</li>
<li>Step 3: Compute the MSE on the remaining group;</li>
<li>Step 4: Repeat the process <span class="math inline">\(k\)</span> times, considering another test group;</li>
<li>Step 5: Estimate the test error by averaging the test errors of each fold.</li>
</ul></li>
<li><em>Question (b)</em></li>
</ul>
<p>On the validation set approach:</p>
<ul>
<li>Advantages: More accurate test error estimation (bias and variance).</li>
<li>Disadvantages: Computationnaly less efficient.</li>
</ul>
<p>On the LOOCV:</p>
<ul>
<li>Advantages: Computationnaly more efficient and more accurate test error estimation (variance).</li>
<li>Disadvantages: Less accurate test error estimation (bias).</li>
</ul>
</div>
<div id="exercise-4.-3" class="section level3">
<h3><span class="header-section-number">5.1.4</span> Exercise 4.</h3>
<p>We can estimate <span class="math inline">\(\widehat{Y}\)</span> by bootstrap samples. Assume <span class="math inline">\(R\)</span> bootstrap samples. So, we obtain <span class="math inline">\(R\)</span> values for <span class="math inline">\(\widehat{Y}\)</span>: <span class="math inline">\(\widehat{Y}_1, \dots, \widehat{Y}_R\)</span>.
And</p>
<p><span class="math display">\[ \bar{\widehat{Y}} = \frac{1}{R}\sum_{i = 1}^R \widehat{Y}_i \quad\text{and}\quad sd(\widehat{Y}) = \left(\frac{1}{R - 1}\sum_{i=1}^R\left(\widehat{Y}_i - \bar{\widehat{Y}}\right)^2\right)^{1/2}.\]</span></p>
</div>
</div>
<div id="applied-exercises-3" class="section level2">
<h2><span class="header-section-number">5.2</span> Applied Exercises</h2>
<div id="exercise-5.-3" class="section level3">
<h3><span class="header-section-number">5.2.1</span> Exercise 5.</h3>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="resampling-methods.html#cb71-1"></a>df &lt;-<span class="st"> </span><span class="kw">as_tibble</span>(Default)</span></code></pre></div>
<ul>
<li><em>Question (a)</em></li>
</ul>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="resampling-methods.html#cb72-1"></a>logit_model &lt;-<span class="st"> </span><span class="kw">glm</span>(default <span class="op">~</span><span class="st"> </span>income <span class="op">+</span><span class="st"> </span>balance, <span class="dt">data =</span> df, <span class="dt">family =</span> <span class="st">&#39;binomial&#39;</span>)</span>
<span id="cb72-2"><a href="resampling-methods.html#cb72-2"></a>logit_model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">print_summary_glm</span>()</span></code></pre></div>
Results of the model on the <strong>df</strong> dataset.
<ul>
<li>
<em>Formula</em>: default ~ income + balance
</li>
<li>
<em>Residuals</em>
</li>
<div style="overflow-x:auto;">
<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Name
</th>
<th style="text-align:right;">
NA_num
</th>
<th style="text-align:right;">
Unique
</th>
<th style="text-align:right;">
Range
</th>
<th style="text-align:right;">
Mean
</th>
<th style="text-align:right;">
Variance
</th>
<th style="text-align:right;">
Minimum
</th>
<th style="text-align:right;">
Q05
</th>
<th style="text-align:right;">
Q10
</th>
<th style="text-align:right;">
Q25
</th>
<th style="text-align:right;">
Q50
</th>
<th style="text-align:right;">
Q75
</th>
<th style="text-align:right;">
Q90
</th>
<th style="text-align:right;">
Q95
</th>
<th style="text-align:right;">
Maximum
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Residuals
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
10000
</td>
<td style="text-align:right;">
6.2
</td>
<td style="text-align:right;">
-0.07
</td>
<td style="text-align:right;">
0.15
</td>
<td style="text-align:right;">
-2.47
</td>
<td style="text-align:right;">
-0.49
</td>
<td style="text-align:right;">
-0.31
</td>
<td style="text-align:right;">
-0.14
</td>
<td style="text-align:right;">
-0.06
</td>
<td style="text-align:right;">
-0.02
</td>
<td style="text-align:right;">
-0.01
</td>
<td style="text-align:right;">
-0.01
</td>
<td style="text-align:right;">
3.72
</td>
</tr>
</tbody>
</table>
</div>
<li>
<em>Coefficients</em>
</li>
<div style="overflow-x:auto;">
<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Variable
</th>
<th style="text-align:right;">
Estimate
</th>
<th style="text-align:right;">
Std. Error
</th>
<th style="text-align:right;">
z value
</th>
<th style="text-align:left;">
Pr(&gt;|z|)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
-11.54047
</td>
<td style="text-align:right;">
0.43476
</td>
<td style="text-align:right;">
-26.54468
</td>
<td style="text-align:left;">
&lt; 2.22e-16
</td>
</tr>
<tr>
<td style="text-align:left;">
income
</td>
<td style="text-align:right;">
0.00002
</td>
<td style="text-align:right;">
0.00000
</td>
<td style="text-align:right;">
4.17418
</td>
<td style="text-align:left;">
2.9906e-05
</td>
</tr>
<tr>
<td style="text-align:left;">
balance
</td>
<td style="text-align:right;">
0.00565
</td>
<td style="text-align:right;">
0.00023
</td>
<td style="text-align:right;">
24.83628
</td>
<td style="text-align:left;">
&lt; 2.22e-16
</td>
</tr>
</tbody>
</table>
</div>
<li>
<em>Null deviance</em>: 2920.65 on 9999 degrees of freedom.
</li>
<li>
<em>Residual deviance</em>: 1578.966 on 9997 degrees of freedom.
</li>
<li>
<em>AIC</em>: 1584.966
</li>
</ul>
<ul>
<li><p><em>Question (b)</em></p></li>
<li><p><em>Question (b.i)</em> Split the sample.</p></li>
</ul>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="resampling-methods.html#cb73-1"></a><span class="kw">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb73-2"><a href="resampling-methods.html#cb73-2"></a>idx &lt;-<span class="st"> </span>df<span class="op">$</span>default <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">createDataPartition</span>(<span class="dt">p =</span> <span class="fl">0.7</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>, <span class="dt">times =</span> <span class="dv">1</span>)</span>
<span id="cb73-3"><a href="resampling-methods.html#cb73-3"></a>train &lt;-<span class="st"> </span>df[idx,]</span>
<span id="cb73-4"><a href="resampling-methods.html#cb73-4"></a>test &lt;-<span class="st"> </span>df[<span class="op">-</span>idx,]</span></code></pre></div>
<ul>
<li><em>Question (b.ii)</em> Fit a logistic regression on the train set.</li>
</ul>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="resampling-methods.html#cb74-1"></a>logit_model &lt;-<span class="st"> </span><span class="kw">glm</span>(default <span class="op">~</span><span class="st"> </span>income <span class="op">+</span><span class="st"> </span>balance, <span class="dt">data =</span> train, <span class="dt">family =</span> <span class="st">&#39;binomial&#39;</span>)</span></code></pre></div>
<ul>
<li><em>Question (b.iii)</em> Prediction on the test set.</li>
</ul>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="resampling-methods.html#cb75-1"></a>pred_prob &lt;-<span class="st"> </span><span class="kw">predict</span>(logit_model, test, <span class="dt">type=</span> <span class="st">&#39;response&#39;</span>)</span>
<span id="cb75-2"><a href="resampling-methods.html#cb75-2"></a>pred &lt;-<span class="st"> </span><span class="kw">if_else</span>(pred_prob <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.5</span>, <span class="st">&#39;Yes&#39;</span>, <span class="st">&#39;No&#39;</span>)</span></code></pre></div>
<ul>
<li><em>Question (b.iv)</em> Compute the validation set error.</li>
</ul>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="resampling-methods.html#cb76-1"></a>misclassif &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(test<span class="op">$</span>default <span class="op">==</span><span class="st"> </span>pred)</span></code></pre></div>
<p>So, there are 2.73% of misclassified on the validation set, which correponds to the validation set error.</p>
<ul>
<li><em>Question (c)</em></li>
</ul>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="resampling-methods.html#cb77-1"></a>misclassif &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&#39;double&#39;</span>, <span class="dv">3</span>)</span>
<span id="cb77-2"><a href="resampling-methods.html#cb77-2"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>){</span>
<span id="cb77-3"><a href="resampling-methods.html#cb77-3"></a>  <span class="kw">set.seed</span>(i)</span>
<span id="cb77-4"><a href="resampling-methods.html#cb77-4"></a>  </span>
<span id="cb77-5"><a href="resampling-methods.html#cb77-5"></a>  idx &lt;-<span class="st"> </span>df<span class="op">$</span>default <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">createDataPartition</span>(<span class="dt">p =</span> <span class="fl">0.7</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>, <span class="dt">times =</span> <span class="dv">1</span>)</span>
<span id="cb77-6"><a href="resampling-methods.html#cb77-6"></a>  train &lt;-<span class="st"> </span>df[idx,]</span>
<span id="cb77-7"><a href="resampling-methods.html#cb77-7"></a>  test &lt;-<span class="st"> </span>df[<span class="op">-</span>idx,]</span>
<span id="cb77-8"><a href="resampling-methods.html#cb77-8"></a>  </span>
<span id="cb77-9"><a href="resampling-methods.html#cb77-9"></a>  logit_model &lt;-<span class="st"> </span><span class="kw">glm</span>(default <span class="op">~</span><span class="st"> </span>income <span class="op">+</span><span class="st"> </span>balance, <span class="dt">data =</span> train, <span class="dt">family =</span> <span class="st">&#39;binomial&#39;</span>)</span>
<span id="cb77-10"><a href="resampling-methods.html#cb77-10"></a>  </span>
<span id="cb77-11"><a href="resampling-methods.html#cb77-11"></a>  pred_prob &lt;-<span class="st"> </span><span class="kw">predict</span>(logit_model, test, <span class="dt">type=</span> <span class="st">&#39;response&#39;</span>)</span>
<span id="cb77-12"><a href="resampling-methods.html#cb77-12"></a>  pred &lt;-<span class="st"> </span><span class="kw">if_else</span>(pred_prob <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.5</span>, <span class="st">&#39;Yes&#39;</span>, <span class="st">&#39;No&#39;</span>)</span>
<span id="cb77-13"><a href="resampling-methods.html#cb77-13"></a>  misclassif[i] &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(test<span class="op">$</span>default <span class="op">==</span><span class="st"> </span>pred)</span>
<span id="cb77-14"><a href="resampling-methods.html#cb77-14"></a>}</span></code></pre></div>
<p>The three misclassification error are respectively 2.6%, 2.77% and 2.53% on each on the validation set. These results are quite close to each others.</p>
<ul>
<li><em>Question (d)</em></li>
</ul>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="resampling-methods.html#cb78-1"></a><span class="kw">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb78-2"><a href="resampling-methods.html#cb78-2"></a>  </span>
<span id="cb78-3"><a href="resampling-methods.html#cb78-3"></a>idx &lt;-<span class="st"> </span>df<span class="op">$</span>default <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">createDataPartition</span>(<span class="dt">p =</span> <span class="fl">0.7</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>, <span class="dt">times =</span> <span class="dv">1</span>)</span>
<span id="cb78-4"><a href="resampling-methods.html#cb78-4"></a>train &lt;-<span class="st"> </span>df[idx,]</span>
<span id="cb78-5"><a href="resampling-methods.html#cb78-5"></a>test &lt;-<span class="st"> </span>df[<span class="op">-</span>idx,]</span>
<span id="cb78-6"><a href="resampling-methods.html#cb78-6"></a>  </span>
<span id="cb78-7"><a href="resampling-methods.html#cb78-7"></a>logit_model &lt;-<span class="st"> </span><span class="kw">glm</span>(default <span class="op">~</span><span class="st"> </span>income <span class="op">+</span><span class="st"> </span>balance <span class="op">+</span><span class="st"> </span>student, <span class="dt">data =</span> train, <span class="dt">family =</span> <span class="st">&#39;binomial&#39;</span>)</span>
<span id="cb78-8"><a href="resampling-methods.html#cb78-8"></a>  </span>
<span id="cb78-9"><a href="resampling-methods.html#cb78-9"></a>pred_prob &lt;-<span class="st"> </span><span class="kw">predict</span>(logit_model, test, <span class="dt">type=</span> <span class="st">&#39;response&#39;</span>)</span>
<span id="cb78-10"><a href="resampling-methods.html#cb78-10"></a>pred &lt;-<span class="st"> </span><span class="kw">if_else</span>(pred_prob <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.5</span>, <span class="st">&#39;Yes&#39;</span>, <span class="st">&#39;No&#39;</span>)</span>
<span id="cb78-11"><a href="resampling-methods.html#cb78-11"></a>misclassif &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(test<span class="op">$</span>default <span class="op">==</span><span class="st"> </span>pred)</span></code></pre></div>
<p>So, there are 2.83% of misclassified on the validation set, which correponds to the validation set error. This result is almost the same as the one of the model without the <code>student</code> feature. So, the inclusion of this feature does not leads to a significant reduction in the test error rate.</p>
</div>
<div id="exercise-6.-3" class="section level3">
<h3><span class="header-section-number">5.2.2</span> Exercise 6.</h3>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="resampling-methods.html#cb79-1"></a>df &lt;-<span class="st"> </span><span class="kw">as_tibble</span>(Default)</span></code></pre></div>
<ul>
<li><em>Question (a)</em></li>
</ul>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="resampling-methods.html#cb80-1"></a>logit_model &lt;-<span class="st"> </span><span class="kw">glm</span>(default <span class="op">~</span><span class="st"> </span>income <span class="op">+</span><span class="st"> </span>balance, <span class="dt">data =</span> df, <span class="dt">family =</span> <span class="st">&#39;binomial&#39;</span>)</span>
<span id="cb80-2"><a href="resampling-methods.html#cb80-2"></a>logit_model_summary &lt;-<span class="st"> </span>logit_model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>()</span></code></pre></div>
<p>The estimation of the coefficient for the <code>ìncome</code> feature is <span class="math inline">\(2.0808976\times 10^{-5}\)</span> with a standard error of <span class="math inline">\(4.9851672\times 10^{-6}\)</span>. And the estimation of the coefficient for the <code>balance</code> feature is <span class="math inline">\(0.0056471\)</span> with a standard error of <span class="math inline">\(2.2737314\times 10^{-4}\)</span>.</p>
<ul>
<li><em>Question (b)</em></li>
</ul>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="resampling-methods.html#cb81-1"></a>boot.fn &lt;-<span class="st"> </span><span class="cf">function</span>(df, index){</span>
<span id="cb81-2"><a href="resampling-methods.html#cb81-2"></a>  <span class="kw">return</span>(<span class="kw">coef</span>(<span class="kw">glm</span>(default <span class="op">~</span><span class="st"> </span>income <span class="op">+</span><span class="st"> </span>balance, <span class="dt">data =</span> df, <span class="dt">subset =</span> index, <span class="dt">family =</span> <span class="st">&#39;binomial&#39;</span>)))</span>
<span id="cb81-3"><a href="resampling-methods.html#cb81-3"></a>}</span></code></pre></div>
<ul>
<li><em>Question (c)</em></li>
</ul>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="resampling-methods.html#cb82-1"></a><span class="kw">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb82-2"><a href="resampling-methods.html#cb82-2"></a>bootstrap_summary &lt;-<span class="st"> </span>boot<span class="op">::</span><span class="kw">boot</span>(<span class="dt">data =</span> df, <span class="dt">statistic =</span> boot.fn, <span class="dt">R =</span> <span class="dv">1000</span>)</span></code></pre></div>
<p>Using the bootstrap method, the estimation of the coefficient for the <code>income</code> feature is <span class="math inline">\(2.0808976\times 10^{-5}\)</span> with a standard error of <span class="math inline">\(5.0734443\times 10^{-6}\)</span>. And the estimation of the coefficient for the <code>balance</code> feature is <span class="math inline">\(0.0056471\)</span> with a standard error of <span class="math inline">\(2.2991334\times 10^{-4}\)</span>.</p>
<ul>
<li><em>Question (d)</em></li>
</ul>
<p>The estimated standard errors obtained with the <code>glm</code> function are slightly smaller than the ones obtained using the bootstrap method. This is due to the fact that the formula for the standard errors rely on some assumptions, and more particularly on an estimation of the noise variance. As we estimate <span class="math inline">\(\sigma^2\)</span> using the RSS, we use the linearaty assumption in our model. So, there is probably a non-linear relationship in the data, and so, the residuals from a linear fit will be inflated and so will <span class="math inline">\(\widehat{\sigma}^2\)</span>. Secondly, the standard formulas assume that the <span class="math inline">\(x_i\)</span> are fixed, and all the variability comes from the variation in the errors <span class="math inline">\(\epsilon_i\)</span>. However, the bootstrap approach does not rely on any of these assumptions, and so it is likely giving a more accurate estimate of the standard errors of the coefficients than the <code>summary</code> function.</p>
</div>
<div id="exercise-7.-3" class="section level3">
<h3><span class="header-section-number">5.2.3</span> Exercise 7.</h3>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="resampling-methods.html#cb83-1"></a>weekly &lt;-<span class="st"> </span><span class="kw">as_tibble</span>(Weekly)</span></code></pre></div>
<ul>
<li><em>Question (a)</em></li>
</ul>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="resampling-methods.html#cb84-1"></a>logit_model &lt;-<span class="st"> </span><span class="kw">glm</span>(Direction <span class="op">~</span><span class="st"> </span>Lag1 <span class="op">+</span><span class="st"> </span>Lag2, <span class="dt">data =</span> weekly, <span class="dt">family =</span> <span class="st">&#39;binomial&#39;</span>)</span></code></pre></div>
<ul>
<li><em>Question (b)</em></li>
</ul>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="resampling-methods.html#cb85-1"></a>logit_model_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">glm</span>(Direction <span class="op">~</span><span class="st"> </span>Lag1 <span class="op">+</span><span class="st"> </span>Lag2, <span class="dt">data =</span> weekly, <span class="dt">subset =</span> <span class="dv">2</span><span class="op">:</span><span class="kw">nrow</span>(weekly), <span class="dt">family =</span> <span class="st">&#39;binomial&#39;</span>)</span></code></pre></div>
<ul>
<li><em>Question (c)</em></li>
</ul>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="resampling-methods.html#cb86-1"></a>pred &lt;-<span class="st"> </span><span class="kw">predict</span>(logit_model_<span class="dv">1</span>, <span class="dt">newdata =</span> weekly[<span class="dv">1</span>, <span class="kw">c</span>(<span class="st">&#39;Lag1&#39;</span>, <span class="st">&#39;Lag2&#39;</span>)], <span class="dt">type =</span> <span class="st">&#39;response&#39;</span>)</span></code></pre></div>
<p>So, the prediction of the direction of the first observation is <strong>Up</strong> (because <span class="math inline">\(\mathbb{P}(Direction = UP | Lag1, Lag2) = 0.5713923\)</span>). This observation is incorrectly classify.</p>
<ul>
<li><em>Question (d)</em></li>
</ul>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="resampling-methods.html#cb87-1"></a>errors &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&#39;logical&#39;</span>, <span class="kw">nrow</span>(weekly))</span>
<span id="cb87-2"><a href="resampling-methods.html#cb87-2"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(weekly)){</span>
<span id="cb87-3"><a href="resampling-methods.html#cb87-3"></a>  model &lt;-<span class="st"> </span><span class="kw">glm</span>(Direction <span class="op">~</span><span class="st"> </span>Lag1 <span class="op">+</span><span class="st"> </span>Lag2, <span class="dt">data =</span> weekly[<span class="op">-</span>i,], <span class="dt">family =</span> <span class="st">&#39;binomial&#39;</span>)</span>
<span id="cb87-4"><a href="resampling-methods.html#cb87-4"></a>  pred_prob &lt;-<span class="st"> </span><span class="kw">predict</span>(model, <span class="dt">newdata =</span> weekly[i, <span class="kw">c</span>(<span class="st">&#39;Lag1&#39;</span>, <span class="st">&#39;Lag2&#39;</span>)], <span class="dt">type =</span> <span class="st">&#39;response&#39;</span>)</span>
<span id="cb87-5"><a href="resampling-methods.html#cb87-5"></a>  pred &lt;-<span class="st"> </span><span class="kw">ifelse</span>(pred_prob <span class="op">&gt;</span><span class="st"> </span><span class="fl">.5</span>, <span class="st">&#39;Up&#39;</span>, <span class="st">&#39;Down&#39;</span>)</span>
<span id="cb87-6"><a href="resampling-methods.html#cb87-6"></a>  errors[i] &lt;-<span class="st"> </span>(weekly[i, <span class="st">&#39;Direction&#39;</span>] <span class="op">!=</span><span class="st"> </span>pred)</span>
<span id="cb87-7"><a href="resampling-methods.html#cb87-7"></a>}</span></code></pre></div>
<ul>
<li><em>Question (e)</em></li>
</ul>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="resampling-methods.html#cb88-1"></a>loocv_error &lt;-<span class="st"> </span><span class="kw">mean</span>(errors)</span></code></pre></div>
<p>The LOOCV estimate for the test error is 0.4499541. The value of the LOOCV estimate is quite small, a bit under <span class="math inline">\(0.5\)</span>. It does indicate that the linear model is not very suitable for this dataset.</p>
</div>
<div id="exercise-8.-3" class="section level3">
<h3><span class="header-section-number">5.2.4</span> Exercise 8.</h3>
<ul>
<li><em>Question (a)</em></li>
</ul>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="resampling-methods.html#cb89-1"></a><span class="kw">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb89-2"><a href="resampling-methods.html#cb89-2"></a>x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>)</span>
<span id="cb89-3"><a href="resampling-methods.html#cb89-3"></a>y &lt;-<span class="st"> </span>x <span class="op">-</span><span class="st"> </span><span class="dv">2</span><span class="op">*</span>x<span class="op">**</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>)</span></code></pre></div>
<p>In this dataset, we have <span class="math inline">\(n = 100\)</span> and <span class="math inline">\(p = 2\)</span>. The model used to generate the data is:
<span class="math display">\[ Y = X - 2X^2 + \epsilon, \quad\text{where}\quad \epsilon \sim \mathcal{N}(0, 1)\]</span></p>
<ul>
<li><em>Question (b)</em></li>
</ul>
<center>
<img src="04-resampling_files/figure-html/ex8b-1.png" width="480" style="display: block; margin: auto;" />
</center>
<p>We see that there is a clear relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> which is not linear.</p>
<ul>
<li><em>Question (c)</em></li>
</ul>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="resampling-methods.html#cb90-1"></a><span class="kw">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb90-2"><a href="resampling-methods.html#cb90-2"></a>cv_errors &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&#39;numeric&#39;</span>, <span class="dv">4</span>)</span>
<span id="cb90-3"><a href="resampling-methods.html#cb90-3"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">4</span>){</span>
<span id="cb90-4"><a href="resampling-methods.html#cb90-4"></a>  model &lt;-<span class="st"> </span><span class="kw">glm</span>(y <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(x, i), <span class="dt">data =</span> df)</span>
<span id="cb90-5"><a href="resampling-methods.html#cb90-5"></a>  cv_errors[i] &lt;-<span class="st"> </span><span class="kw">cv.glm</span>(df, model)<span class="op">$</span>delta[<span class="dv">1</span>]</span>
<span id="cb90-6"><a href="resampling-methods.html#cb90-6"></a>}</span></code></pre></div>
<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
<tbody>
<tr>
<td style="text-align:left;font-weight: bold;">
Model
</td>
<td style="text-align:left;">
Linear
</td>
<td style="text-align:left;">
Quadratic
</td>
<td style="text-align:left;">
Cubic
</td>
<td style="text-align:left;">
Quadric
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
LOOCV Errors
</td>
<td style="text-align:left;">
10.9659305
</td>
<td style="text-align:left;">
0.8858076
</td>
<td style="text-align:left;">
0.9087144
</td>
<td style="text-align:left;">
0.9644779
</td>
</tr>
</tbody>
</table>
<ul>
<li><em>Question (d)</em></li>
</ul>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="resampling-methods.html#cb91-1"></a><span class="kw">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb91-2"><a href="resampling-methods.html#cb91-2"></a>cv_errors &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&#39;numeric&#39;</span>, <span class="dv">4</span>)</span>
<span id="cb91-3"><a href="resampling-methods.html#cb91-3"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">4</span>){</span>
<span id="cb91-4"><a href="resampling-methods.html#cb91-4"></a>  model &lt;-<span class="st"> </span><span class="kw">glm</span>(y <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(x, i), <span class="dt">data =</span> df)</span>
<span id="cb91-5"><a href="resampling-methods.html#cb91-5"></a>  cv_errors[i] &lt;-<span class="st"> </span><span class="kw">cv.glm</span>(df, model)<span class="op">$</span>delta[<span class="dv">1</span>]</span>
<span id="cb91-6"><a href="resampling-methods.html#cb91-6"></a>}</span></code></pre></div>
<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
<tbody>
<tr>
<td style="text-align:left;font-weight: bold;">
Model
</td>
<td style="text-align:left;">
Linear
</td>
<td style="text-align:left;">
Quadratic
</td>
<td style="text-align:left;">
Cubic
</td>
<td style="text-align:left;">
Quadric
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
LOOCV Errors
</td>
<td style="text-align:left;">
10.9659305
</td>
<td style="text-align:left;">
0.8858076
</td>
<td style="text-align:left;">
0.9087144
</td>
<td style="text-align:left;">
0.9644779
</td>
</tr>
</tbody>
</table>
<p>The LOOCV errors are exactly the same when we use another seed because we predict every observation using all the other ones which in fact involve no randomness.</p>
<ul>
<li><em>Question (e)</em></li>
</ul>
<p>The model which the smallest LOOCV error is the quadratic model which makes sense because data are generated using this model.</p>
<ul>
<li><em>Question (f)</em></li>
</ul>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="resampling-methods.html#cb92-1"></a>model &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(x, <span class="dv">4</span>), <span class="dt">data =</span> df)</span>
<span id="cb92-2"><a href="resampling-methods.html#cb92-2"></a>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">print_summary_lm</span>()</span></code></pre></div>
Results of the linear model on the <strong>df</strong> dataset.
<ul>
<li>
<em>Formula</em>: y ~ poly(x, 4)
</li>
<li>
<em>Residuals</em>
</li>
<div style="overflow-x:auto;">
<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Name
</th>
<th style="text-align:right;">
NA_num
</th>
<th style="text-align:right;">
Unique
</th>
<th style="text-align:right;">
Range
</th>
<th style="text-align:right;">
Mean
</th>
<th style="text-align:right;">
Variance
</th>
<th style="text-align:right;">
Minimum
</th>
<th style="text-align:right;">
Q05
</th>
<th style="text-align:right;">
Q10
</th>
<th style="text-align:right;">
Q25
</th>
<th style="text-align:right;">
Q50
</th>
<th style="text-align:right;">
Q75
</th>
<th style="text-align:right;">
Q90
</th>
<th style="text-align:right;">
Q95
</th>
<th style="text-align:right;">
Maximum
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Residuals
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
100
</td>
<td style="text-align:right;">
4.54
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.8
</td>
<td style="text-align:right;">
-1.68
</td>
<td style="text-align:right;">
-1.44
</td>
<td style="text-align:right;">
-1.13
</td>
<td style="text-align:right;">
-0.59
</td>
<td style="text-align:right;">
-0.05
</td>
<td style="text-align:right;">
0.57
</td>
<td style="text-align:right;">
1.2
</td>
<td style="text-align:right;">
1.54
</td>
<td style="text-align:right;">
2.86
</td>
</tr>
</tbody>
</table>
</div>
<li>
<em>Coefficients</em>
</li>
<div style="overflow-x:auto;">
<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Variable
</th>
<th style="text-align:right;">
Estimate
</th>
<th style="text-align:right;">
Std. Error
</th>
<th style="text-align:right;">
t value
</th>
<th style="text-align:left;">
Pr(&gt;|t|)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
-2.20424
</td>
<td style="text-align:right;">
0.09144
</td>
<td style="text-align:right;">
-24.10521
</td>
<td style="text-align:left;">
&lt; 2e-16
</td>
</tr>
<tr>
<td style="text-align:left;">
poly(x, 4)1
</td>
<td style="text-align:right;">
19.51809
</td>
<td style="text-align:right;">
0.91443
</td>
<td style="text-align:right;">
21.34464
</td>
<td style="text-align:left;">
&lt; 2e-16
</td>
</tr>
<tr>
<td style="text-align:left;">
poly(x, 4)2
</td>
<td style="text-align:right;">
-30.12292
</td>
<td style="text-align:right;">
0.91443
</td>
<td style="text-align:right;">
-32.94189
</td>
<td style="text-align:left;">
&lt; 2e-16
</td>
</tr>
<tr>
<td style="text-align:left;">
poly(x, 4)3
</td>
<td style="text-align:right;">
0.27121
</td>
<td style="text-align:right;">
0.91443
</td>
<td style="text-align:right;">
0.29659
</td>
<td style="text-align:left;">
0.76743
</td>
</tr>
<tr>
<td style="text-align:left;">
poly(x, 4)4
</td>
<td style="text-align:right;">
1.15503
</td>
<td style="text-align:right;">
0.91443
</td>
<td style="text-align:right;">
1.26312
</td>
<td style="text-align:left;">
0.20964
</td>
</tr>
</tbody>
</table>
</div>
<li>
<em>Residual standard error</em>: 0.914 on 95 degrees of freedom.
</li>
<li>
<em>Multiple <span class="math inline">\(R^2\)</span></em>: 0.942.
</li>
<li>
<em>Adjusted <span class="math inline">\(R^2\)</span></em>: 0.94.
</li>
<li>
<em>F-statistic</em>: 385.611 on 4 and 95, p-value: &lt;2e-16.
</li>
</ul>
<p>The coefficients that are statistically significant are the ones for <span class="math inline">\(X\)</span> and <span class="math inline">\(X^2\)</span> which correspond to the results given by the cross-validation.</p>
</div>
<div id="exercise-9.-3" class="section level3">
<h3><span class="header-section-number">5.2.5</span> Exercise 9.</h3>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="resampling-methods.html#cb93-1"></a>boston &lt;-<span class="st"> </span><span class="kw">as_tibble</span>(Boston)</span></code></pre></div>
<ul>
<li><em>Question (a)</em></li>
</ul>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="resampling-methods.html#cb94-1"></a>mu_hat &lt;-<span class="st"> </span><span class="kw">mean</span>(boston<span class="op">$</span>medv)</span></code></pre></div>
<p>The estimate of the mean of <code>medv</code> is 22.5328063.</p>
<ul>
<li><em>Question (b)</em></li>
</ul>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="resampling-methods.html#cb95-1"></a>se_mu_hat &lt;-<span class="st"> </span><span class="kw">sd</span>(boston<span class="op">$</span>medv) <span class="op">/</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">nrow</span>(boston))</span></code></pre></div>
<p>So, a <span class="math inline">\(95\%\)</span> confidence interval fot the mean of <code>medv</code> is <span class="math inline">\(22.5328063 \pm 2\times0.4088611\)</span>.</p>
<ul>
<li><em>Question (c)</em></li>
</ul>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="resampling-methods.html#cb96-1"></a>mean.fn &lt;-<span class="st"> </span><span class="cf">function</span>(data, index) <span class="kw">return</span>(<span class="kw">mean</span>(data[index]))</span>
<span id="cb96-2"><a href="resampling-methods.html#cb96-2"></a>mu_boot &lt;-<span class="st"> </span><span class="kw">boot</span>(boston<span class="op">$</span>medv, <span class="dt">statistic =</span> mean.fn, <span class="dt">R =</span> <span class="dv">1000</span>)</span></code></pre></div>
<p>The standard error of <span class="math inline">\(\widehat{\mu}\)</span> using the bootstrap is <span class="math inline">\(0.4097547\)</span> which is very close to <span class="math inline">\(0.4088611\)</span> (the one found in question (b)).</p>
<ul>
<li><em>Question (d)</em></li>
</ul>
<p>Based on the bootstrap estimate, a <span class="math inline">\(95\%\)</span> confidence interval for the mean of <code>medv</code> is <span class="math inline">\([21.713297, 23.3523157]\)</span>. The one found with <code>t.test(boston$medv)</code> is <span class="math inline">\([21.729528, 23.3360846]\)</span>. Both of the intervals are very similar.</p>
<ul>
<li><em>Question (e)</em></li>
</ul>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb97-1"><a href="resampling-methods.html#cb97-1"></a>med_hat &lt;-<span class="st"> </span><span class="kw">median</span>(boston<span class="op">$</span>medv)</span></code></pre></div>
<p>The estimate of the median of <code>medv</code> is 21.2.</p>
<ul>
<li><em>Question (f)</em></li>
</ul>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="resampling-methods.html#cb98-1"></a>median.fn &lt;-<span class="st"> </span><span class="cf">function</span>(data, index) <span class="kw">return</span>(<span class="kw">median</span>(data[index]))</span>
<span id="cb98-2"><a href="resampling-methods.html#cb98-2"></a>median_boot &lt;-<span class="st"> </span><span class="kw">boot</span>(boston<span class="op">$</span>medv, <span class="dt">statistic =</span> median.fn, <span class="dt">R =</span> <span class="dv">1000</span>)</span></code></pre></div>
<p>The standard error of <span class="math inline">\(\widehat{\mu}_{med}\)</span> using the bootstrap is <span class="math inline">\(0.3770327\)</span> .</p>
<ul>
<li><em>Question (g)</em></li>
</ul>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="resampling-methods.html#cb99-1"></a>quant_hat &lt;-<span class="st"> </span><span class="kw">quantile</span>(boston<span class="op">$</span>medv, <span class="dt">probs =</span> <span class="fl">0.1</span>)</span></code></pre></div>
<p>The estimate of the tenth percentile of <code>medv</code> is 12.75.</p>
<ul>
<li><em>Question (h)</em></li>
</ul>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="resampling-methods.html#cb100-1"></a>quant.fn &lt;-<span class="st"> </span><span class="cf">function</span>(data, index) <span class="kw">return</span>(<span class="kw">quantile</span>(data[index], <span class="dt">probs =</span> <span class="fl">0.1</span>))</span>
<span id="cb100-2"><a href="resampling-methods.html#cb100-2"></a>quant_boot &lt;-<span class="st"> </span><span class="kw">boot</span>(boston<span class="op">$</span>medv, <span class="dt">statistic =</span> quant.fn, <span class="dt">R =</span> <span class="dv">1000</span>)</span></code></pre></div>
<p>The standard error of <span class="math inline">\(\widehat{\mu}_{0.1}\)</span> using the bootstrap is <span class="math inline">\(0.4923\)</span> .</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="classification.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="linear-model-selection-and-regularization.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
