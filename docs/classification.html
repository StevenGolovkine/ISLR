<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Classification | An Introduction to Statistical Learning</title>
  <meta name="description" content="This book aims to provide my results to the different exercises of An Introduction to Statistical Learning, with Application in R, by James, Witten, Hastie and Tibshirani." />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Classification | An Introduction to Statistical Learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book aims to provide my results to the different exercises of An Introduction to Statistical Learning, with Application in R, by James, Witten, Hastie and Tibshirani." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Classification | An Introduction to Statistical Learning" />
  
  <meta name="twitter:description" content="This book aims to provide my results to the different exercises of An Introduction to Statistical Learning, with Application in R, by James, Witten, Hastie and Tibshirani." />
  

<meta name="author" content="Steven Golovkine" />


<meta name="date" content="2020-03-24" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="linear-regression.html"/>
<link rel="next" href="resampling-methods.html"/>
<script src="libs/header-attrs-2.1/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Statistical Learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="overview.html"><a href="overview.html"><i class="fa fa-check"></i><b>2</b> An Overview of Statistical Learning</a>
<ul>
<li class="chapter" data-level="2.1" data-path="overview.html"><a href="overview.html#conceptual-exercises"><i class="fa fa-check"></i><b>2.1</b> Conceptual Exercises</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="overview.html"><a href="overview.html#exercise-1."><i class="fa fa-check"></i><b>2.1.1</b> Exercise 1.</a></li>
<li class="chapter" data-level="2.1.2" data-path="overview.html"><a href="overview.html#exercise-2."><i class="fa fa-check"></i><b>2.1.2</b> Exercise 2.</a></li>
<li class="chapter" data-level="2.1.3" data-path="overview.html"><a href="overview.html#exercise-3."><i class="fa fa-check"></i><b>2.1.3</b> Exercise 3.</a></li>
<li class="chapter" data-level="2.1.4" data-path="overview.html"><a href="overview.html#exercise-4."><i class="fa fa-check"></i><b>2.1.4</b> Exercise 4.</a></li>
<li class="chapter" data-level="2.1.5" data-path="overview.html"><a href="overview.html#exercise-5."><i class="fa fa-check"></i><b>2.1.5</b> Exercise 5.</a></li>
<li class="chapter" data-level="2.1.6" data-path="overview.html"><a href="overview.html#exercise-6."><i class="fa fa-check"></i><b>2.1.6</b> Exercise 6.</a></li>
<li class="chapter" data-level="2.1.7" data-path="overview.html"><a href="overview.html#exercise-7."><i class="fa fa-check"></i><b>2.1.7</b> Exercise 7.</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="overview.html"><a href="overview.html#applied-exercises"><i class="fa fa-check"></i><b>2.2</b> Applied Exercises</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="overview.html"><a href="overview.html#exercise-8."><i class="fa fa-check"></i><b>2.2.1</b> Exercise 8.</a></li>
<li class="chapter" data-level="2.2.2" data-path="overview.html"><a href="overview.html#exercise-9."><i class="fa fa-check"></i><b>2.2.2</b> Exercise 9.</a></li>
<li class="chapter" data-level="2.2.3" data-path="overview.html"><a href="overview.html#exercise-10."><i class="fa fa-check"></i><b>2.2.3</b> Exercise 10.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>3</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="linear-regression.html"><a href="linear-regression.html#conceptual-exercises-1"><i class="fa fa-check"></i><b>3.1</b> Conceptual Exercises</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="linear-regression.html"><a href="linear-regression.html#exercise-1.-1"><i class="fa fa-check"></i><b>3.1.1</b> Exercise 1.</a></li>
<li class="chapter" data-level="3.1.2" data-path="linear-regression.html"><a href="linear-regression.html#exercise-2.-1"><i class="fa fa-check"></i><b>3.1.2</b> Exercise 2.</a></li>
<li class="chapter" data-level="3.1.3" data-path="linear-regression.html"><a href="linear-regression.html#exercise-3.-1"><i class="fa fa-check"></i><b>3.1.3</b> Exercise 3.</a></li>
<li class="chapter" data-level="3.1.4" data-path="linear-regression.html"><a href="linear-regression.html#exercise-4.-1"><i class="fa fa-check"></i><b>3.1.4</b> Exercise 4.</a></li>
<li class="chapter" data-level="3.1.5" data-path="linear-regression.html"><a href="linear-regression.html#exercise-5.-1"><i class="fa fa-check"></i><b>3.1.5</b> Exercise 5.</a></li>
<li class="chapter" data-level="3.1.6" data-path="linear-regression.html"><a href="linear-regression.html#exercise-6.-1"><i class="fa fa-check"></i><b>3.1.6</b> Exercise 6.</a></li>
<li class="chapter" data-level="3.1.7" data-path="linear-regression.html"><a href="linear-regression.html#exercise-7.-1"><i class="fa fa-check"></i><b>3.1.7</b> Exercise 7.</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="linear-regression.html"><a href="linear-regression.html#applied-exercises-1"><i class="fa fa-check"></i><b>3.2</b> Applied Exercises</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="linear-regression.html"><a href="linear-regression.html#exercise-8.-1"><i class="fa fa-check"></i><b>3.2.1</b> Exercise 8.</a></li>
<li class="chapter" data-level="3.2.2" data-path="linear-regression.html"><a href="linear-regression.html#exercise-9.-1"><i class="fa fa-check"></i><b>3.2.2</b> Exercise 9.</a></li>
<li class="chapter" data-level="3.2.3" data-path="linear-regression.html"><a href="linear-regression.html#exercise-10.-1"><i class="fa fa-check"></i><b>3.2.3</b> Exercise 10.</a></li>
<li class="chapter" data-level="3.2.4" data-path="linear-regression.html"><a href="linear-regression.html#exercise-11."><i class="fa fa-check"></i><b>3.2.4</b> Exercise 11.</a></li>
<li class="chapter" data-level="3.2.5" data-path="linear-regression.html"><a href="linear-regression.html#exercise-12."><i class="fa fa-check"></i><b>3.2.5</b> Exercise 12.</a></li>
<li class="chapter" data-level="3.2.6" data-path="linear-regression.html"><a href="linear-regression.html#exercise-13."><i class="fa fa-check"></i><b>3.2.6</b> Exercise 13.</a></li>
<li class="chapter" data-level="3.2.7" data-path="linear-regression.html"><a href="linear-regression.html#exercise-14."><i class="fa fa-check"></i><b>3.2.7</b> Exercise 14.</a></li>
<li class="chapter" data-level="3.2.8" data-path="linear-regression.html"><a href="linear-regression.html#exercise-15."><i class="fa fa-check"></i><b>3.2.8</b> Exercise 15.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>4</b> Classification</a>
<ul>
<li class="chapter" data-level="4.1" data-path="classification.html"><a href="classification.html#conceptual-exercises-2"><i class="fa fa-check"></i><b>4.1</b> Conceptual Exercises</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="classification.html"><a href="classification.html#exercise-1.-2"><i class="fa fa-check"></i><b>4.1.1</b> Exercise 1.</a></li>
<li class="chapter" data-level="4.1.2" data-path="classification.html"><a href="classification.html#exercise-2.-2"><i class="fa fa-check"></i><b>4.1.2</b> Exercise 2.</a></li>
<li class="chapter" data-level="4.1.3" data-path="classification.html"><a href="classification.html#exercise-3.-2"><i class="fa fa-check"></i><b>4.1.3</b> Exercise 3.</a></li>
<li class="chapter" data-level="4.1.4" data-path="classification.html"><a href="classification.html#exercise-4.-2"><i class="fa fa-check"></i><b>4.1.4</b> Exercise 4.</a></li>
<li class="chapter" data-level="4.1.5" data-path="classification.html"><a href="classification.html#exercise-5.-2"><i class="fa fa-check"></i><b>4.1.5</b> Exercise 5.</a></li>
<li class="chapter" data-level="4.1.6" data-path="classification.html"><a href="classification.html#exercise-6.-2"><i class="fa fa-check"></i><b>4.1.6</b> Exercise 6.</a></li>
<li class="chapter" data-level="4.1.7" data-path="classification.html"><a href="classification.html#exercise-7.-2"><i class="fa fa-check"></i><b>4.1.7</b> Exercise 7.</a></li>
<li class="chapter" data-level="4.1.8" data-path="classification.html"><a href="classification.html#exercise-8.-2"><i class="fa fa-check"></i><b>4.1.8</b> Exercise 8.</a></li>
<li class="chapter" data-level="4.1.9" data-path="classification.html"><a href="classification.html#exercise-9.-2"><i class="fa fa-check"></i><b>4.1.9</b> Exercise 9.</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="classification.html"><a href="classification.html#applied-exercises-2"><i class="fa fa-check"></i><b>4.2</b> Applied Exercises</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="classification.html"><a href="classification.html#exercise-10.-2"><i class="fa fa-check"></i><b>4.2.1</b> Exercise 10.</a></li>
<li class="chapter" data-level="4.2.2" data-path="classification.html"><a href="classification.html#exercise-11.-1"><i class="fa fa-check"></i><b>4.2.2</b> Exercise 11.</a></li>
<li class="chapter" data-level="4.2.3" data-path="classification.html"><a href="classification.html#exercise-12.-1"><i class="fa fa-check"></i><b>4.2.3</b> Exercise 12.</a></li>
<li class="chapter" data-level="4.2.4" data-path="classification.html"><a href="classification.html#exercise-13.-1"><i class="fa fa-check"></i><b>4.2.4</b> Exercise 13.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="resampling-methods.html"><a href="resampling-methods.html"><i class="fa fa-check"></i><b>5</b> Resampling Methods</a>
<ul>
<li class="chapter" data-level="5.1" data-path="resampling-methods.html"><a href="resampling-methods.html#conceptual-exercises-3"><i class="fa fa-check"></i><b>5.1</b> Conceptual Exercises</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="resampling-methods.html"><a href="resampling-methods.html#exercise-1.-3"><i class="fa fa-check"></i><b>5.1.1</b> Exercise 1.</a></li>
<li class="chapter" data-level="5.1.2" data-path="resampling-methods.html"><a href="resampling-methods.html#exercise-2.-3"><i class="fa fa-check"></i><b>5.1.2</b> Exercise 2.</a></li>
<li class="chapter" data-level="5.1.3" data-path="resampling-methods.html"><a href="resampling-methods.html#exercise-3.-3"><i class="fa fa-check"></i><b>5.1.3</b> Exercise 3.</a></li>
<li class="chapter" data-level="5.1.4" data-path="resampling-methods.html"><a href="resampling-methods.html#exercise-4.-3"><i class="fa fa-check"></i><b>5.1.4</b> Exercise 4.</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="resampling-methods.html"><a href="resampling-methods.html#applied-exercises-3"><i class="fa fa-check"></i><b>5.2</b> Applied Exercises</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="resampling-methods.html"><a href="resampling-methods.html#exercise-5.-3"><i class="fa fa-check"></i><b>5.2.1</b> Exercise 5.</a></li>
<li class="chapter" data-level="5.2.2" data-path="resampling-methods.html"><a href="resampling-methods.html#exercise-6.-3"><i class="fa fa-check"></i><b>5.2.2</b> Exercise 6.</a></li>
<li class="chapter" data-level="5.2.3" data-path="resampling-methods.html"><a href="resampling-methods.html#exercise-7.-3"><i class="fa fa-check"></i><b>5.2.3</b> Exercise 7.</a></li>
<li class="chapter" data-level="5.2.4" data-path="resampling-methods.html"><a href="resampling-methods.html#exercise-8.-3"><i class="fa fa-check"></i><b>5.2.4</b> Exercise 8.</a></li>
<li class="chapter" data-level="5.2.5" data-path="resampling-methods.html"><a href="resampling-methods.html#exercise-9.-3"><i class="fa fa-check"></i><b>5.2.5</b> Exercise 9.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html"><i class="fa fa-check"></i><b>6</b> Linear Model Selection and Regularization</a>
<ul>
<li class="chapter" data-level="6.1" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#conceptual-exercises-4"><i class="fa fa-check"></i><b>6.1</b> Conceptual Exercises</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#exercise-1.-4"><i class="fa fa-check"></i><b>6.1.1</b> Exercise 1.</a></li>
<li class="chapter" data-level="6.1.2" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#exercise-2.-4"><i class="fa fa-check"></i><b>6.1.2</b> Exercise 2.</a></li>
<li class="chapter" data-level="6.1.3" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#exercise-3.-4"><i class="fa fa-check"></i><b>6.1.3</b> Exercise 3.</a></li>
<li class="chapter" data-level="6.1.4" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#exercise-4.-4"><i class="fa fa-check"></i><b>6.1.4</b> Exercise 4.</a></li>
<li class="chapter" data-level="6.1.5" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#exercise-5.-4"><i class="fa fa-check"></i><b>6.1.5</b> Exercise 5.</a></li>
<li class="chapter" data-level="6.1.6" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#exercise-6.-4"><i class="fa fa-check"></i><b>6.1.6</b> Exercise 6.</a></li>
<li class="chapter" data-level="6.1.7" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#exercise-7.-4"><i class="fa fa-check"></i><b>6.1.7</b> Exercise 7.</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#applied-exercises-4"><i class="fa fa-check"></i><b>6.2</b> Applied Exercises</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#exercise-8.-4"><i class="fa fa-check"></i><b>6.2.1</b> Exercise 8.</a></li>
<li class="chapter" data-level="6.2.2" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#exercise-9.-4"><i class="fa fa-check"></i><b>6.2.2</b> Exercise 9.</a></li>
<li class="chapter" data-level="6.2.3" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#exercise-10.-3"><i class="fa fa-check"></i><b>6.2.3</b> Exercise 10.</a></li>
<li class="chapter" data-level="6.2.4" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#exercise-11.-2"><i class="fa fa-check"></i><b>6.2.4</b> Exercise 11.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html"><i class="fa fa-check"></i><b>7</b> Moving Beyond Linearity</a>
<ul>
<li class="chapter" data-level="7.1" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#conceptual-exercises-5"><i class="fa fa-check"></i><b>7.1</b> Conceptual exercises</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#exercise-1.-5"><i class="fa fa-check"></i><b>7.1.1</b> Exercise 1.</a></li>
<li class="chapter" data-level="7.1.2" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#exercise-2.-5"><i class="fa fa-check"></i><b>7.1.2</b> Exercise 2.</a></li>
<li class="chapter" data-level="7.1.3" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#exercise-3.-5"><i class="fa fa-check"></i><b>7.1.3</b> Exercise 3.</a></li>
<li class="chapter" data-level="7.1.4" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#exercise-4.-5"><i class="fa fa-check"></i><b>7.1.4</b> Exercise 4.</a></li>
<li class="chapter" data-level="7.1.5" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#exercise-5.-5"><i class="fa fa-check"></i><b>7.1.5</b> Exercise 5.</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#applied-exercises-5"><i class="fa fa-check"></i><b>7.2</b> Applied exercises</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#exercise-6.-5"><i class="fa fa-check"></i><b>7.2.1</b> Exercise 6.</a></li>
<li class="chapter" data-level="7.2.2" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#exercise-7.-5"><i class="fa fa-check"></i><b>7.2.2</b> Exercise 7.</a></li>
<li class="chapter" data-level="7.2.3" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#exercise-8.-5"><i class="fa fa-check"></i><b>7.2.3</b> Exercise 8.</a></li>
<li class="chapter" data-level="7.2.4" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#exercise-9.-5"><i class="fa fa-check"></i><b>7.2.4</b> Exercise 9.</a></li>
<li class="chapter" data-level="7.2.5" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#exercise-10.-4"><i class="fa fa-check"></i><b>7.2.5</b> Exercise 10.</a></li>
<li class="chapter" data-level="7.2.6" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#exercise-11.-3"><i class="fa fa-check"></i><b>7.2.6</b> Exercise 11.</a></li>
<li class="chapter" data-level="7.2.7" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#exercise-12.-2"><i class="fa fa-check"></i><b>7.2.7</b> Exercise 12.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="tree-based-methods.html"><a href="tree-based-methods.html"><i class="fa fa-check"></i><b>8</b> Tree-based methods</a>
<ul>
<li class="chapter" data-level="8.1" data-path="tree-based-methods.html"><a href="tree-based-methods.html#conceptual-exercises-6"><i class="fa fa-check"></i><b>8.1</b> Conceptual exercises</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="tree-based-methods.html"><a href="tree-based-methods.html#exercise-1.-6"><i class="fa fa-check"></i><b>8.1.1</b> Exercise 1.</a></li>
<li class="chapter" data-level="8.1.2" data-path="tree-based-methods.html"><a href="tree-based-methods.html#exercise-2.-6"><i class="fa fa-check"></i><b>8.1.2</b> Exercise 2.</a></li>
<li class="chapter" data-level="8.1.3" data-path="tree-based-methods.html"><a href="tree-based-methods.html#exercise-3.-6"><i class="fa fa-check"></i><b>8.1.3</b> Exercise 3.</a></li>
<li class="chapter" data-level="8.1.4" data-path="tree-based-methods.html"><a href="tree-based-methods.html#exercise-4.-6"><i class="fa fa-check"></i><b>8.1.4</b> Exercise 4.</a></li>
<li class="chapter" data-level="8.1.5" data-path="tree-based-methods.html"><a href="tree-based-methods.html#exercise-5.-6"><i class="fa fa-check"></i><b>8.1.5</b> Exercise 5.</a></li>
<li class="chapter" data-level="8.1.6" data-path="tree-based-methods.html"><a href="tree-based-methods.html#exercise-6.-6"><i class="fa fa-check"></i><b>8.1.6</b> Exercise 6.</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="tree-based-methods.html"><a href="tree-based-methods.html#applied-exercises-6"><i class="fa fa-check"></i><b>8.2</b> Applied exercises</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="tree-based-methods.html"><a href="tree-based-methods.html#exercise-7.-6"><i class="fa fa-check"></i><b>8.2.1</b> Exercise 7.</a></li>
<li class="chapter" data-level="8.2.2" data-path="tree-based-methods.html"><a href="tree-based-methods.html#exercise-8.-6"><i class="fa fa-check"></i><b>8.2.2</b> Exercise 8.</a></li>
<li class="chapter" data-level="8.2.3" data-path="tree-based-methods.html"><a href="tree-based-methods.html#exercise-9.-6"><i class="fa fa-check"></i><b>8.2.3</b> Exercise 9.</a></li>
<li class="chapter" data-level="8.2.4" data-path="tree-based-methods.html"><a href="tree-based-methods.html#exercise-10.-5"><i class="fa fa-check"></i><b>8.2.4</b> Exercise 10.</a></li>
<li class="chapter" data-level="8.2.5" data-path="tree-based-methods.html"><a href="tree-based-methods.html#exercise-11.-4"><i class="fa fa-check"></i><b>8.2.5</b> Exercise 11.</a></li>
<li class="chapter" data-level="8.2.6" data-path="tree-based-methods.html"><a href="tree-based-methods.html#exercise-12.-3"><i class="fa fa-check"></i><b>8.2.6</b> Exercise 12.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="support-vector-machines.html"><a href="support-vector-machines.html"><i class="fa fa-check"></i><b>9</b> Support Vector Machines</a>
<ul>
<li class="chapter" data-level="9.1" data-path="support-vector-machines.html"><a href="support-vector-machines.html#conceptual-exercises-7"><i class="fa fa-check"></i><b>9.1</b> Conceptual exercises</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="support-vector-machines.html"><a href="support-vector-machines.html#exercise-1.-7"><i class="fa fa-check"></i><b>9.1.1</b> Exercise 1.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Statistical Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="classification" class="section level1" number="4">
<h1><span class="header-section-number">Chapter 4</span> Classification</h1>
<div id="conceptual-exercises-2" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Conceptual Exercises</h2>
<div id="exercise-1.-2" class="section level3" number="4.1.1">
<h3><span class="header-section-number">4.1.1</span> Exercise 1.</h3>
<p>Proof that the logistic function representation and logit representation for the logistic regression model are equivalent.</p>
<p><span class="math display">\[p(x) = \frac{\exp(\beta_0 + \beta_1x)}{1 - \exp(\beta_0 + \beta_1x)} \quad\text{and}\quad 1 - p(x) = \frac{1}{1 - \exp(\beta_0 + \beta_1x)}\]</span></p>
<p>So,
<span class="math display">\[\frac{p(x)}{1 - p(x)} = \exp(\beta_0 + \beta_1x)\]</span></p>
</div>
<div id="exercise-2.-2" class="section level3" number="4.1.2">
<h3><span class="header-section-number">4.1.2</span> Exercise 2.</h3>
<p>Asume that the observations in the <span class="math inline">\(k\)</span>-th classes are drawn from a <span class="math inline">\(\mathcal{N}(\mu_k, \sigma^2)\)</span>-distribution. Proof that the Bayes classifier assigns an observation to the class for which the discriminant function is maximised.</p>
<p><span class="math display">\[p(x) = \frac{\pi_k\frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{1}{2\sigma^2}\left(x - \mu_k\right)^2\right)}{\prod_{l=1}^{K}\pi_l\frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{1}{2\sigma^2}\left(x - \mu_l\right)^2\right)} = C\pi_k\exp\left(-\frac{1}{2\sigma^2}\left(x - \mu_k\right)^2\right),\]</span></p>
<p>where <span class="math inline">\(C\)</span> is constant with respect to <span class="math inline">\(k\)</span>.
By taking the logarithm of <span class="math inline">\(p(x)\)</span>, we find:</p>
<p><span class="math display">\[\log(p(x)) = \log{C} + \log{\pi_k} - \frac{1}{2\sigma^2}\left(x - \mu_k\right)^2 = \log{C} + \log{\pi_k} - \frac{x^2}{2\sigma^2} + \frac{x\mu_k}{\sigma^2} + \frac{\mu_k^2}{2\sigma^2}.\]</span></p>
<p>So, maximising <span class="math inline">\(p(x)\)</span> with respect to <span class="math inline">\(k\)</span> is equivalent to maximising <span class="math inline">\(\delta_k(x) = \log{\pi_k} + \frac{x\mu_k}{\sigma^2} + \frac{\mu_k^2}{2\sigma^2}\)</span> with respect to <span class="math inline">\(k\)</span>.</p>
</div>
<div id="exercise-3.-2" class="section level3" number="4.1.3">
<h3><span class="header-section-number">4.1.3</span> Exercise 3.</h3>
<p>Assume there is only one feature which come from an one-dimensional normal distribution. If an observation belongs to the <span class="math inline">\(k\)</span>-th classe, <span class="math inline">\(X\)</span> have a <span class="math inline">\(\mathcal{N}(\mu_k, \sigma_k^2)\)</span> distribution.</p>
<p>The probability that <span class="math inline">\(X = x\)</span> belongs to the class <span class="math inline">\(k\)</span> is:</p>
<p><span class="math display">\[ p_k(x) = \frac{\pi_k\frac{1}{\sqrt{2\pi\sigma_k^2}}\exp\left(-\frac{1}{2\sigma_k^2}\left(x - \mu_k\right)^2\right)}{\prod_{l=1}^{K}\pi_l\frac{1}{\sqrt{2\pi\sigma_l^2}}\exp\left(-\frac{1}{2\sigma_l^2}\left(x - \mu_l\right)^2\right)}\]</span></p>
<p>By taking the logarithm of <span class="math inline">\(p_k(x)\)</span>, we find:</p>
<p><span class="math display">\[\log(p(x)) = \log{C} + \log{\pi_k} -\frac{1}{2}\log(\sigma_k) - \frac{1}{2\sigma_k^2}\left(x - \mu_k\right)^2.\]</span>
where <span class="math inline">\(C\)</span> is constant with respect to <span class="math inline">\(k\)</span>.
The Bayes classifier involves assigning <span class="math inline">\(X = x\)</span> to <span class="math inline">\(\arg \max_k p_k(x)\)</span> which is equal to <span class="math inline">\(\arg \max_k \left(\log{\pi_k} -\frac{1}{2}\log(\sigma_k) - \frac{1}{2\sigma_k^2}\left(x - \mu_k\right)^2\right)\)</span>. So, the Bayes classifier is quadratic is this case.</p>
</div>
<div id="exercise-4.-2" class="section level3" number="4.1.4">
<h3><span class="header-section-number">4.1.4</span> Exercise 4.</h3>
<p>This exercise is about the curse of dimensionality.</p>
<ul>
<li><em>Question (a)</em></li>
</ul>
<p>We aim to predict the response of a new observation <span class="math inline">\(X\)</span> using only observations that are within 10% of the range of <span class="math inline">\(X\)</span> closest to that test observation. As the range of <span class="math inline">\(X\)</span> is <span class="math inline">\([0, 1]\)</span>, we only consider observation points that are in the interval <span class="math inline">\([X-0.5, X+0.5]\)</span>. On average, 10% of the available observations will be used to make the predictions.</p>
<ul>
<li><em>Question (b)</em></li>
</ul>
<p>We aim to do the same but in dimension 2. On average, only 1% of the observations will be used to make the predictions. It corresponds to 10% on hte first axis and 10% on the second axis (<span class="math inline">\(1\% = 10\% \times 10\%\)</span>).</p>
<ul>
<li><em>Question (c)</em></li>
</ul>
<p>Now, we want to do the same but in dimension 100. On average, there are few points within 10% of the range of each direction of <span class="math inline">\(X\)</span>. Indeed, there are <span class="math inline">\(10\%^{100}\)</span> points in this area.</p>
<ul>
<li><em>Question (d)</em></li>
</ul>
<p>When we want to consider 10% of the range of each of the <span class="math inline">\(p\)</span> features, the proportion of available data that is used is <span class="math inline">\(10\%^p\)</span>. When <span class="math inline">\(p\)</span> grows, <span class="math inline">\(10\%^p\)</span> becomes smaller and smaller. So, when <span class="math inline">\(p\)</span> is large, there are very few observations in the <span class="math inline">\(10\%\)</span> range of the observation.</p>
<ul>
<li><em>Question (e)</em></li>
</ul>
<p>We want <span class="math inline">\(10\%\)</span> observations that are in an hypercube around the new observations. Note <span class="math inline">\(l\)</span> the length of each side of the hypercube. In order to have 10% of the data to predict the response of the new observation, we should have <span class="math inline">\(l^p = 0.1\)</span>. So, the length of each side of the hypercube is <span class="math inline">\(l = (0.1)^{1/p}\)</span>. If <span class="math inline">\(p = 1\)</span>, the length is <span class="math inline">\(0.1\)</span>, if <span class="math inline">\(p = 2, l = 0.31\)</span> and if <span class="math inline">\(p = 100, l = 0.98\)</span>. Given that the maximum size of the hypercube is <span class="math inline">\(1\)</span>, having an hypercube of length <span class="math inline">\(0.98\)</span> to get 10% of the data when <span class="math inline">\(p = 100\)</span> is something very annoying. See <em>The Elements of Statistical Learning</em>, by Hastie, Tibshirani and Friedman for more information.</p>
</div>
<div id="exercise-5.-2" class="section level3" number="4.1.5">
<h3><span class="header-section-number">4.1.5</span> Exercise 5.</h3>
<p>This exercise is about the differences between LDA and QDA.</p>
<ul>
<li><em>Question (a)</em></li>
</ul>
<p>Assume that the Bayes decision boundary is linear. QDA may be better on the training set in case of overfitting. But, LDA should be better on the test set.</p>
<ul>
<li><em>Question (b)</em></li>
</ul>
<p>QDA should be better than LDA on both the training and test sets because it allows more flexibility.</p>
<ul>
<li><em>Question (c)</em></li>
</ul>
<p>The test prediction accuracy should increase with the sample size for QDA if the Bayes decision boundary is non-linear. However, usually, more observations mean better knowledge on the true decision boundary.</p>
<ul>
<li><em>Question (d)</em></li>
</ul>
<p>QDA is not flexible enough to model linear decision as good as LDA. So, the test arror rate of QDA will not be better than the one of LDA if the Bayes decision boundary is linear. Mathematically speaking, this is because the coefficient in front of the quadratic term in QDA can not null. As exemple, you can take a look at the figure 4.11).</p>
</div>
<div id="exercise-6.-2" class="section level3" number="4.1.6">
<h3><span class="header-section-number">4.1.6</span> Exercise 6.</h3>
<ul>
<li><em>Question (a)</em></li>
</ul>
<p><span class="math display">\[
\begin{align} 
\mathbb{P}(Y = A \mid X_1 = 40, X_2 = 3.5) &amp;= \frac{\exp(-6+0.05\times 40 + 1 \times 3.5)}{1 + \exp(-6+0.05\times 40 + 1 \times 3.5)} \\&amp;= 0.377
\end{align}
\]</span></p>
<p>The probability that a student who studies 40 hours and has an undergrad GPA of 3.5 gets an A is 38%.</p>
<ul>
<li><em>Question (b)</em></li>
</ul>
<p><span class="math display">\[
\begin{align} 
\mathbb{P}(Y = A \mid X_1 = x, X_2 = 3.5) &gt; 0.5 &amp;\Longleftrightarrow \frac{\exp(-6+0.05\times x + 1 \times 3.5)}{1 + \exp(-6+0.05\times x + 1 \times 3.5)} &gt; 0.5 \\
  &amp;\Longleftrightarrow \exp(-6+0.05\times x + 1 \times 3.5) &gt; 1 \\
  &amp;\Longleftrightarrow -6+0.05\times x + 1 \times 3.5 &gt; 0 \\
  &amp;\Longleftrightarrow x &gt; 50 \\
\end{align}
\]</span></p>
<p>A student with an undergrad GPA of 3.5 needs to studies 50 hours to have 50% chance of getting an A in the class.</p>
</div>
<div id="exercise-7.-2" class="section level3" number="4.1.7">
<h3><span class="header-section-number">4.1.7</span> Exercise 7.</h3>
<p><span class="math display">\[
\begin{align} 
\mathbb{P}(Y = &quot;yes&quot; \mid X = 4) &amp;= \frac{0.8f_1(4)}{0.8f_1(4) + 0.2f_2(4)} \quad\text{where} f_1 \sim \mathcal{N}(10, 36) \text{ and } f_2 \sim \mathcal{N}(0, 36)
\\&amp;= 0.75
\end{align}
\]</span></p>
<p>A company with a percentage profit of 4% last year have 75% chance to issue dividend this year.</p>
</div>
<div id="exercise-8.-2" class="section level3" number="4.1.8">
<h3><span class="header-section-number">4.1.8</span> Exercise 8.</h3>
<p>The error rates for the logistic regression is quite high. So, it might imply that the Bayes decision boundary is (higly) non-linear. Thus, 1-NN should be prefered for new observations. However, 1-NN usually overfits. It is possible that there is an error of 0% on the training set and 36% on the test sets. So, we can not conclude on which method is better.</p>
</div>
<div id="exercise-9.-2" class="section level3" number="4.1.9">
<h3><span class="header-section-number">4.1.9</span> Exercise 9.</h3>
<p>This exercise is about odds. Note <span class="math inline">\(p_{def}\)</span> the default probability.</p>
<ul>
<li><em>Question (a)</em></li>
</ul>
<p><span class="math display">\[ \frac{p_{def}}{1 - p_{def}} = 0.37 \Longleftrightarrow 1.37p_{def} = 0.37 \Longleftrightarrow p_{def} = 0.27%%\]</span></p>
<p>On average, 27% of people with an odds of 0.37 of defaulting on their credit cards payment will default.</p>
<ul>
<li><em>Question (b)</em></li>
</ul>
<p><span class="math display">\[ odd = \frac{p_{def}}{1 - p_{def}} = \frac{0.16}{1 - 0.16} = 0.19 \]</span></p>
<p>A person with a percentage of changce to default of 16% on their credit card payment has an odd of 0.19.</p>
</div>
</div>
<div id="applied-exercises-2" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Applied Exercises</h2>
<div id="exercise-10.-2" class="section level3" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Exercise 10.</h3>
<p>This exercise is about fitting a simple logistic model to the <code>Weekly</code> dataset. It contains 1089 observations of 9 variables about the weekly percentage returns for the S&amp;P 500 stock index between 1990 and 2010. For a description of the variables, please refer to <strong>R</strong> by typing <code>help(Weekly)</code> after loading the package <code>ISLR</code>.</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="classification.html#cb45-1"></a>weekly &lt;-<span class="st"> </span><span class="kw">as_tibble</span>(Weekly, <span class="dt">rownames =</span> <span class="ot">NA</span>)</span></code></pre></div>
<ul>
<li><em>Question (a)</em></li>
</ul>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="classification.html#cb46-1"></a>weekly <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary_df</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">print_summary_df</span>()</span></code></pre></div>
<ul>
<li>
<strong>Factor variables</strong>
</li>
<ul>
<li>
Direction
</li>
<div style="overflow-x:auto;">
<table class="kable_wrapper table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
<tbody>
<tr>
<td>
<table>
<thead>
<tr>
<th style="text-align:left;">
Direction
</th>
<th style="text-align:right;">
Count
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Down
</td>
<td style="text-align:right;">
484
</td>
</tr>
<tr>
<td style="text-align:left;">
Up
</td>
<td style="text-align:right;">
605
</td>
</tr>
</tbody>
</table>
</td>
</tr>
</tbody>
</table>
</div>
</ul>
</ul>
<ul>
<li>
<strong>Numeric variables</strong>
</li>
<div style="overflow-x:auto;">
<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Name
</th>
<th style="text-align:right;">
NA_num
</th>
<th style="text-align:right;">
Unique
</th>
<th style="text-align:right;">
Range
</th>
<th style="text-align:right;">
Mean
</th>
<th style="text-align:right;">
Variance
</th>
<th style="text-align:right;">
Minimum
</th>
<th style="text-align:right;">
Q05
</th>
<th style="text-align:right;">
Q10
</th>
<th style="text-align:right;">
Q25
</th>
<th style="text-align:right;">
Q50
</th>
<th style="text-align:right;">
Q75
</th>
<th style="text-align:right;">
Q90
</th>
<th style="text-align:right;">
Q95
</th>
<th style="text-align:right;">
Maximum
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Year
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
21
</td>
<td style="text-align:right;">
20.000000
</td>
<td style="text-align:right;">
2000.05
</td>
<td style="text-align:right;">
36.40
</td>
<td style="text-align:right;">
1990.000000
</td>
<td style="text-align:right;">
1991.000000
</td>
<td style="text-align:right;">
1992.00000
</td>
<td style="text-align:right;">
1995.000000
</td>
<td style="text-align:right;">
2000.00000
</td>
<td style="text-align:right;">
2005.000000
</td>
<td style="text-align:right;">
2008.000000
</td>
<td style="text-align:right;">
2009.000000
</td>
<td style="text-align:right;">
2010.000000
</td>
</tr>
<tr>
<td style="text-align:left;">
Lag1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1004
</td>
<td style="text-align:right;">
30.221000
</td>
<td style="text-align:right;">
0.15
</td>
<td style="text-align:right;">
5.56
</td>
<td style="text-align:right;">
-18.195000
</td>
<td style="text-align:right;">
-3.629600
</td>
<td style="text-align:right;">
-2.43040
</td>
<td style="text-align:right;">
-1.154000
</td>
<td style="text-align:right;">
0.24100
</td>
<td style="text-align:right;">
1.405000
</td>
<td style="text-align:right;">
2.807000
</td>
<td style="text-align:right;">
3.737600
</td>
<td style="text-align:right;">
12.026000
</td>
</tr>
<tr>
<td style="text-align:left;">
Lag2
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1005
</td>
<td style="text-align:right;">
30.221000
</td>
<td style="text-align:right;">
0.15
</td>
<td style="text-align:right;">
5.56
</td>
<td style="text-align:right;">
-18.195000
</td>
<td style="text-align:right;">
-3.629600
</td>
<td style="text-align:right;">
-2.43040
</td>
<td style="text-align:right;">
-1.154000
</td>
<td style="text-align:right;">
0.24100
</td>
<td style="text-align:right;">
1.409000
</td>
<td style="text-align:right;">
2.807000
</td>
<td style="text-align:right;">
3.737600
</td>
<td style="text-align:right;">
12.026000
</td>
</tr>
<tr>
<td style="text-align:left;">
Lag3
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1005
</td>
<td style="text-align:right;">
30.221000
</td>
<td style="text-align:right;">
0.15
</td>
<td style="text-align:right;">
5.57
</td>
<td style="text-align:right;">
-18.195000
</td>
<td style="text-align:right;">
-3.667600
</td>
<td style="text-align:right;">
-2.44100
</td>
<td style="text-align:right;">
-1.158000
</td>
<td style="text-align:right;">
0.24100
</td>
<td style="text-align:right;">
1.409000
</td>
<td style="text-align:right;">
2.807000
</td>
<td style="text-align:right;">
3.737600
</td>
<td style="text-align:right;">
12.026000
</td>
</tr>
<tr>
<td style="text-align:left;">
Lag4
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1005
</td>
<td style="text-align:right;">
30.221000
</td>
<td style="text-align:right;">
0.15
</td>
<td style="text-align:right;">
5.57
</td>
<td style="text-align:right;">
-18.195000
</td>
<td style="text-align:right;">
-3.667600
</td>
<td style="text-align:right;">
-2.44100
</td>
<td style="text-align:right;">
-1.158000
</td>
<td style="text-align:right;">
0.23800
</td>
<td style="text-align:right;">
1.409000
</td>
<td style="text-align:right;">
2.807000
</td>
<td style="text-align:right;">
3.737600
</td>
<td style="text-align:right;">
12.026000
</td>
</tr>
<tr>
<td style="text-align:left;">
Lag5
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1005
</td>
<td style="text-align:right;">
30.221000
</td>
<td style="text-align:right;">
0.14
</td>
<td style="text-align:right;">
5.58
</td>
<td style="text-align:right;">
-18.195000
</td>
<td style="text-align:right;">
-3.667600
</td>
<td style="text-align:right;">
-2.44520
</td>
<td style="text-align:right;">
-1.166000
</td>
<td style="text-align:right;">
0.23400
</td>
<td style="text-align:right;">
1.405000
</td>
<td style="text-align:right;">
2.798200
</td>
<td style="text-align:right;">
3.737600
</td>
<td style="text-align:right;">
12.026000
</td>
</tr>
<tr>
<td style="text-align:left;">
Volume
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1089
</td>
<td style="text-align:right;">
9.240749
</td>
<td style="text-align:right;">
1.57
</td>
<td style="text-align:right;">
2.84
</td>
<td style="text-align:right;">
0.087465
</td>
<td style="text-align:right;">
0.167552
</td>
<td style="text-align:right;">
0.19555
</td>
<td style="text-align:right;">
0.332022
</td>
<td style="text-align:right;">
1.00268
</td>
<td style="text-align:right;">
2.053727
</td>
<td style="text-align:right;">
4.365844
</td>
<td style="text-align:right;">
5.310663
</td>
<td style="text-align:right;">
9.328214
</td>
</tr>
<tr>
<td style="text-align:left;">
Today
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1003
</td>
<td style="text-align:right;">
30.221000
</td>
<td style="text-align:right;">
0.15
</td>
<td style="text-align:right;">
5.56
</td>
<td style="text-align:right;">
-18.195000
</td>
<td style="text-align:right;">
-3.629600
</td>
<td style="text-align:right;">
-2.43040
</td>
<td style="text-align:right;">
-1.154000
</td>
<td style="text-align:right;">
0.24100
</td>
<td style="text-align:right;">
1.405000
</td>
<td style="text-align:right;">
2.807000
</td>
<td style="text-align:right;">
3.737600
</td>
<td style="text-align:right;">
12.026000
</td>
</tr>
</tbody>
</table>
</div>
</ul>
<div class="figure" style="text-align: center"><span id="fig:ex10aii"></span>
<img src="03-classification_files/figure-html/ex10aii-1.png" alt="Pair plots." width="1440" />
<p class="caption">
Figure 4.1: Pair plots.
</p>
</div>
<p>We see a strong exponential pattern between the <code>Year</code> and <code>Volume</code> features.</p>
<ul>
<li><em>Question (b)</em></li>
</ul>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="classification.html#cb47-1"></a>logit_model &lt;-<span class="st"> </span><span class="kw">glm</span>(Direction <span class="op">~</span><span class="st"> </span>Lag1 <span class="op">+</span><span class="st"> </span>Lag2 <span class="op">+</span><span class="st"> </span>Lag3 <span class="op">+</span><span class="st"> </span>Lag4 <span class="op">+</span><span class="st"> </span>Lag5 <span class="op">+</span><span class="st"> </span>Volume, <span class="dt">data =</span> weekly, <span class="dt">family =</span> <span class="st">&#39;binomial&#39;</span>)</span>
<span id="cb47-2"><a href="classification.html#cb47-2"></a>logit_model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">print_summary_glm</span>()</span></code></pre></div>
Results of the model on the <strong>weekly</strong> dataset.
<ul>
<li>
<em>Formula</em>: Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume
</li>
<li>
<em>Residuals</em>
</li>
<div style="overflow-x:auto;">
<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Name
</th>
<th style="text-align:right;">
NA_num
</th>
<th style="text-align:right;">
Unique
</th>
<th style="text-align:right;">
Range
</th>
<th style="text-align:right;">
Mean
</th>
<th style="text-align:right;">
Variance
</th>
<th style="text-align:right;">
Minimum
</th>
<th style="text-align:right;">
Q05
</th>
<th style="text-align:right;">
Q10
</th>
<th style="text-align:right;">
Q25
</th>
<th style="text-align:right;">
Q50
</th>
<th style="text-align:right;">
Q75
</th>
<th style="text-align:right;">
Q90
</th>
<th style="text-align:right;">
Q95
</th>
<th style="text-align:right;">
Maximum
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Residuals
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1089
</td>
<td style="text-align:right;">
3.15
</td>
<td style="text-align:right;">
0.04
</td>
<td style="text-align:right;">
1.36
</td>
<td style="text-align:right;">
-1.69
</td>
<td style="text-align:right;">
-1.35
</td>
<td style="text-align:right;">
-1.32
</td>
<td style="text-align:right;">
-1.26
</td>
<td style="text-align:right;">
0.99
</td>
<td style="text-align:right;">
1.08
</td>
<td style="text-align:right;">
1.14
</td>
<td style="text-align:right;">
1.17
</td>
<td style="text-align:right;">
1.46
</td>
</tr>
</tbody>
</table>
</div>
<li>
<em>Coefficients</em>
</li>
<div style="overflow-x:auto;">
<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Variable
</th>
<th style="text-align:right;">
Estimate
</th>
<th style="text-align:right;">
Std. Error
</th>
<th style="text-align:right;">
z value
</th>
<th style="text-align:left;">
Pr(&gt;|z|)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
0.26686
</td>
<td style="text-align:right;">
0.08593
</td>
<td style="text-align:right;">
3.10561
</td>
<td style="text-align:left;">
0.0018988
</td>
</tr>
<tr>
<td style="text-align:left;">
Lag1
</td>
<td style="text-align:right;">
-0.04127
</td>
<td style="text-align:right;">
0.02641
</td>
<td style="text-align:right;">
-1.56261
</td>
<td style="text-align:left;">
0.1181444
</td>
</tr>
<tr>
<td style="text-align:left;">
Lag2
</td>
<td style="text-align:right;">
0.05844
</td>
<td style="text-align:right;">
0.02686
</td>
<td style="text-align:right;">
2.17538
</td>
<td style="text-align:left;">
0.0296014
</td>
</tr>
<tr>
<td style="text-align:left;">
Lag3
</td>
<td style="text-align:right;">
-0.01606
</td>
<td style="text-align:right;">
0.02666
</td>
<td style="text-align:right;">
-0.60238
</td>
<td style="text-align:left;">
0.5469239
</td>
</tr>
<tr>
<td style="text-align:left;">
Lag4
</td>
<td style="text-align:right;">
-0.02779
</td>
<td style="text-align:right;">
0.02646
</td>
<td style="text-align:right;">
-1.05014
</td>
<td style="text-align:left;">
0.2936533
</td>
</tr>
<tr>
<td style="text-align:left;">
Lag5
</td>
<td style="text-align:right;">
-0.01447
</td>
<td style="text-align:right;">
0.02638
</td>
<td style="text-align:right;">
-0.54850
</td>
<td style="text-align:left;">
0.5833482
</td>
</tr>
<tr>
<td style="text-align:left;">
Volume
</td>
<td style="text-align:right;">
-0.02274
</td>
<td style="text-align:right;">
0.03690
</td>
<td style="text-align:right;">
-0.61633
</td>
<td style="text-align:left;">
0.5376748
</td>
</tr>
</tbody>
</table>
</div>
<li>
<em>Null deviance</em>: 1496.202 on 1088 degrees of freedom.
</li>
<li>
<em>Residual deviance</em>: 1486.357 on 1082 degrees of freedom.
</li>
<li>
<em>AIC</em>: 1500.357
</li>
</ul>
<p>Only one predictor appears to be statistically signicant in this model, the <code>Lag2</code> feature.</p>
<ul>
<li><em>Question (c)</em></li>
</ul>
<p>The function <code>predict.glm</code> gives the probability of the market going up between two weeks. This can be verified using the command <code>contrasts(weekly$Direction)</code>.</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="classification.html#cb48-1"></a>logit_prob &lt;-<span class="st"> </span><span class="kw">predict.glm</span>(logit_model, <span class="dt">type =</span> <span class="st">&#39;response&#39;</span>)</span>
<span id="cb48-2"><a href="classification.html#cb48-2"></a>logit_pred &lt;-<span class="st"> </span><span class="kw">if_else</span>(logit_prob <span class="op">&gt;</span><span class="st"> </span><span class="fl">.5</span>, <span class="st">&#39;Up&#39;</span>, <span class="st">&#39;Down&#39;</span>)</span></code></pre></div>
<center>
<div class="figure" style="text-align: center"><span id="fig:ex10c3"></span>
<img src="03-classification_files/figure-html/ex10c3-1.png" alt="Confusion matrix for the complete logistic model." width="192" />
<p class="caption">
Figure 4.2: Confusion matrix for the complete logistic model.
</p>
</div>
</center>
<p>The percentage of correct prediction of the movement of the market is 56.1%. However, if we set <code>Up</code> for avery prediction of the <code>Direction</code> variable, we will have a percentage of correct prediction of 55.6. So, the logistic regression improves very slightly the prediction accuracy. And, as we perform the prediction on the training set, it tends to overestimate the errors rate. The results on unseen data might (and should) be worse.</p>
<ul>
<li><em>Question (d)</em></li>
</ul>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="classification.html#cb49-1"></a>mask &lt;-<span class="st"> </span>(weekly<span class="op">$</span>Year <span class="op">&gt;=</span><span class="st"> </span><span class="dv">1990</span> <span class="op">&amp;</span><span class="st"> </span>weekly<span class="op">$</span>Year <span class="op">&lt;=</span><span class="st"> </span><span class="dv">2008</span>)</span>
<span id="cb49-2"><a href="classification.html#cb49-2"></a>train &lt;-<span class="st"> </span>weekly[mask,]</span>
<span id="cb49-3"><a href="classification.html#cb49-3"></a>test &lt;-<span class="st"> </span>weekly[<span class="op">!</span>mask,]</span></code></pre></div>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="classification.html#cb50-1"></a>logit_model &lt;-<span class="st"> </span><span class="kw">glm</span>(Direction <span class="op">~</span><span class="st"> </span>Lag2, <span class="dt">data =</span> train, <span class="dt">family =</span> <span class="st">&#39;binomial&#39;</span>)</span>
<span id="cb50-2"><a href="classification.html#cb50-2"></a>logit_prob &lt;-<span class="st"> </span><span class="kw">predict</span>(logit_model, <span class="dt">newdata =</span> test, <span class="dt">type =</span> <span class="st">&#39;response&#39;</span>)</span>
<span id="cb50-3"><a href="classification.html#cb50-3"></a>logit_pred &lt;-<span class="st"> </span><span class="kw">if_else</span>(logit_prob <span class="op">&gt;</span><span class="st"> </span><span class="fl">.5</span>, <span class="st">&#39;Up&#39;</span>, <span class="st">&#39;Down&#39;</span>)</span></code></pre></div>
<center>
<div class="figure" style="text-align: center"><span id="fig:ex10d3"></span>
<img src="03-classification_files/figure-html/ex10d3-1.png" alt="Confusion matrix for the logistic model on the test set." width="192" />
<p class="caption">
Figure 4.3: Confusion matrix for the logistic model on the test set.
</p>
</div>
</center>
<p>The percentage of correct prediction of the movement of the market on the test set is 62.5% for the logistic model.</p>
<ul>
<li><em>Question (e)</em></li>
</ul>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="classification.html#cb51-1"></a>lda_model &lt;-<span class="st"> </span><span class="kw">lda</span>(Direction <span class="op">~</span><span class="st"> </span>Lag2, <span class="dt">data =</span> train)</span>
<span id="cb51-2"><a href="classification.html#cb51-2"></a>lda_prob &lt;-<span class="st"> </span><span class="kw">predict</span>(lda_model, test)<span class="op">$</span>posterior[, <span class="st">&#39;Up&#39;</span>]</span>
<span id="cb51-3"><a href="classification.html#cb51-3"></a>lda_pred &lt;-<span class="st"> </span><span class="kw">if_else</span>(lda_prob <span class="op">&gt;</span><span class="st"> </span><span class="fl">.5</span>, <span class="st">&#39;Up&#39;</span>, <span class="st">&#39;Down&#39;</span>)</span></code></pre></div>
<center>
<div class="figure" style="text-align: center"><span id="fig:ex10e2"></span>
<img src="03-classification_files/figure-html/ex10e2-1.png" alt="Confusion matrix for the LDA model on the test set." width="192" />
<p class="caption">
Figure 4.4: Confusion matrix for the LDA model on the test set.
</p>
</div>
</center>
<p>The percentage of correct prediction of the movement of the market on the test set is 62.5% for the LDA model.</p>
<ul>
<li><em>Question (f)</em></li>
</ul>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="classification.html#cb52-1"></a>qda_model &lt;-<span class="st"> </span><span class="kw">qda</span>(Direction <span class="op">~</span><span class="st"> </span>Lag2, <span class="dt">data =</span> train)</span>
<span id="cb52-2"><a href="classification.html#cb52-2"></a>qda_prob &lt;-<span class="st"> </span><span class="kw">predict</span>(qda_model, test)<span class="op">$</span>posterior[, <span class="st">&#39;Up&#39;</span>]</span>
<span id="cb52-3"><a href="classification.html#cb52-3"></a>qda_pred &lt;-<span class="st"> </span><span class="kw">if_else</span>(qda_prob <span class="op">&gt;</span><span class="st"> </span><span class="fl">.5</span>, <span class="st">&#39;Up&#39;</span>, <span class="st">&#39;Down&#39;</span>)</span></code></pre></div>
<center>
<div class="figure" style="text-align: center"><span id="fig:ex10f2"></span>
<img src="03-classification_files/figure-html/ex10f2-1.png" alt="Confusion matrix for the QDA model on the test set." width="192" />
<p class="caption">
Figure 4.5: Confusion matrix for the QDA model on the test set.
</p>
</div>
</center>
<p>The percentage of correct prediction of the movement of the market on the test set is 58.7% for the QDA model.</p>
<ul>
<li><em>Question (h)</em></li>
</ul>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="classification.html#cb53-1"></a>knn_model &lt;-<span class="st"> </span><span class="kw">knn</span>(train[, <span class="st">&#39;Lag2&#39;</span>], test[, <span class="st">&#39;Lag2&#39;</span>], train<span class="op">$</span>Direction, <span class="dt">k =</span> <span class="dv">1</span>)</span></code></pre></div>
<center>
<div class="figure" style="text-align: center"><span id="fig:ex10g2"></span>
<img src="03-classification_files/figure-html/ex10g2-1.png" alt="Confusion matrix for the $K$-NN model on the test set." width="192" />
<p class="caption">
Figure 4.6: Confusion matrix for the <span class="math inline">\(K\)</span>-NN model on the test set.
</p>
</div>
</center>
<p>The percentage of correct prediction of the movement of the market on the test set is 51% for the <span class="math inline">\(K\)</span>-NN model with <span class="math inline">\(K = 1\)</span>.</p>
<ul>
<li><em>Question (g)</em></li>
</ul>
<p>Depending on what we want to emphasize, different methods provide the best results. If we are interested by the total accuracy (the number of good prediction), we should use the logistic model or the LDA model. But, if we want to just be good on the prediction of the <code>Up</code>, we must consider the QDA model (but the results on the <code>Down</code> prediction will be awful). The <span class="math inline">\(K\)</span>-NN does not provide good results, it really seems to overfit the training data.</p>
<ul>
<li><em>Question (i)</em></li>
</ul>
<p>As none of the features (except <code>Lag2</code>) appear to be statistically significant in the logistic model, it seems unlikely that adding a combinaison of these features in the models will lead to better results. However, we can try to change the <span class="math inline">\(K\)</span> in the <span class="math inline">\(K\)</span>-NN algorithm to reduce the overfitting.</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="classification.html#cb54-1"></a><span class="kw">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb54-2"><a href="classification.html#cb54-2"></a>errors_rate &lt;-<span class="st"> </span><span class="kw">c</span>()</span>
<span id="cb54-3"><a href="classification.html#cb54-3"></a>k &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">20</span>, <span class="dt">by =</span> <span class="dv">1</span>)</span>
<span id="cb54-4"><a href="classification.html#cb54-4"></a><span class="cf">for</span>(i <span class="cf">in</span> k){</span>
<span id="cb54-5"><a href="classification.html#cb54-5"></a>  knn_model &lt;-<span class="st"> </span><span class="kw">knn</span>(train[, <span class="st">&#39;Lag2&#39;</span>], test[, <span class="st">&#39;Lag2&#39;</span>], train<span class="op">$</span>Direction, <span class="dt">k =</span> i)</span>
<span id="cb54-6"><a href="classification.html#cb54-6"></a>  errors_rate &lt;-<span class="st"> </span><span class="kw">c</span>(errors_rate, <span class="kw">round</span>(<span class="dv">100</span><span class="op">*</span><span class="kw">mean</span>(knn_model <span class="op">==</span><span class="st"> </span>test<span class="op">$</span>Direction), <span class="dv">1</span>))</span>
<span id="cb54-7"><a href="classification.html#cb54-7"></a>}</span>
<span id="cb54-8"><a href="classification.html#cb54-8"></a>df &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">k =</span> <span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">20</span>, <span class="dt">by =</span> <span class="dv">1</span>), errors_rate)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ex10i3"></span>
<img src="03-classification_files/figure-html/ex10i3-1.png" alt="Evolution of percentage of correct predictions compared to $K$." width="960" />
<p class="caption">
Figure 4.7: Evolution of percentage of correct predictions compared to <span class="math inline">\(K\)</span>.
</p>
</div>
<p>For the <span class="math inline">\(K\)</span>-NN model, we obtain the best results for <span class="math inline">\(K\)</span> between 10 and 17. But, even here, the results are not as good as the ones of the logistic model and the LDA model.</p>
</div>
<div id="exercise-11.-1" class="section level3" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> Exercise 11.</h3>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="classification.html#cb55-1"></a>auto &lt;-<span class="st"> </span><span class="kw">as_tibble</span>(Auto)</span></code></pre></div>
<ul>
<li><em>Question (a)</em></li>
</ul>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="classification.html#cb56-1"></a>auto &lt;-<span class="st"> </span>auto <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb56-2"><a href="classification.html#cb56-2"></a><span class="st">          </span><span class="kw">mutate</span>(<span class="dt">mpg01 =</span> <span class="kw">if_else</span>(mpg <span class="op">&gt;</span><span class="st"> </span><span class="kw">median</span>(mpg), <span class="dv">1</span>, <span class="dv">0</span>)) <span class="op">%&gt;%</span></span>
<span id="cb56-3"><a href="classification.html#cb56-3"></a><span class="st">          </span><span class="kw">mutate</span>(<span class="dt">mpg01 =</span> <span class="kw">as_factor</span>(mpg01)) <span class="op">%&gt;%</span></span>
<span id="cb56-4"><a href="classification.html#cb56-4"></a><span class="st">          </span><span class="kw">select</span>(<span class="op">-</span><span class="kw">c</span>(mpg, name))</span></code></pre></div>
<ul>
<li><em>Question (b)</em></li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:ex10bii"></span>
<img src="03-classification_files/figure-html/ex10bii-1.png" alt="Pair plots." width="1440" />
<p class="caption">
Figure 4.8: Pair plots.
</p>
</div>
<p>Based on the pairs plot, four variables seem to be associated with the variable <code>mpg01</code> and could be used to predict its value. These variables are <code>cylinders</code>, <code>displacement</code>, <code>horsepower</code> and <code>weight</code>. However, some of them appears to be particularly correlated (in particular, <code>displacement</code> with <code>horsepower</code> and <code>weight</code>). So, we have to be careful to not had redundant information in the model.</p>
<ul>
<li><em>Question (c)</em></li>
</ul>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="classification.html#cb57-1"></a><span class="kw">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb57-2"><a href="classification.html#cb57-2"></a>idx &lt;-<span class="st"> </span>auto<span class="op">$</span>mpg01 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">createDataPartition</span>(<span class="dt">p =</span> <span class="fl">0.7</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>, <span class="dt">times =</span> <span class="dv">1</span>)</span>
<span id="cb57-3"><a href="classification.html#cb57-3"></a>train &lt;-<span class="st"> </span>auto[idx, ]</span>
<span id="cb57-4"><a href="classification.html#cb57-4"></a>test &lt;-<span class="st"> </span>auto[<span class="op">-</span>idx, ]</span></code></pre></div>
<ul>
<li><em>Question (d)</em></li>
</ul>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="classification.html#cb58-1"></a>lda_model &lt;-<span class="st"> </span><span class="kw">lda</span>(mpg01 <span class="op">~</span><span class="st"> </span>cylinders <span class="op">+</span><span class="st"> </span>displacement <span class="op">+</span><span class="st"> </span>horsepower <span class="op">+</span><span class="st"> </span>weight, <span class="dt">data =</span> train)</span>
<span id="cb58-2"><a href="classification.html#cb58-2"></a>lda_prob &lt;-<span class="st"> </span><span class="kw">predict</span>(lda_model, test)<span class="op">$</span>posterior[, <span class="st">&#39;1&#39;</span>]</span>
<span id="cb58-3"><a href="classification.html#cb58-3"></a>lda_pred &lt;-<span class="st"> </span><span class="kw">if_else</span>(lda_prob <span class="op">&gt;</span><span class="st"> </span><span class="fl">.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span></code></pre></div>
<center>
<div class="figure" style="text-align: center"><span id="fig:ex11d2"></span>
<img src="03-classification_files/figure-html/ex11d2-1.png" alt="Confusion matrix for the LDA model on the test set." width="192" />
<p class="caption">
Figure 4.9: Confusion matrix for the LDA model on the test set.
</p>
</div>
</center>
<p>The test error of the LDA model is 0.09.</p>
<ul>
<li><em>Question (e)</em></li>
</ul>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="classification.html#cb59-1"></a>qda_model &lt;-<span class="st"> </span><span class="kw">qda</span>(mpg01 <span class="op">~</span><span class="st"> </span>cylinders <span class="op">+</span><span class="st"> </span>displacement <span class="op">+</span><span class="st"> </span>horsepower <span class="op">+</span><span class="st"> </span>weight, <span class="dt">data =</span> train)</span>
<span id="cb59-2"><a href="classification.html#cb59-2"></a>qda_prob &lt;-<span class="st"> </span><span class="kw">predict</span>(qda_model, test)<span class="op">$</span>posterior[, <span class="st">&#39;1&#39;</span>]</span>
<span id="cb59-3"><a href="classification.html#cb59-3"></a>qda_pred &lt;-<span class="st"> </span><span class="kw">if_else</span>(qda_prob <span class="op">&gt;</span><span class="st"> </span><span class="fl">.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span></code></pre></div>
<center>
<div class="figure" style="text-align: center"><span id="fig:ex11e2"></span>
<img src="03-classification_files/figure-html/ex11e2-1.png" alt="Confusion matrix for the QDA model on the test set." width="192" />
<p class="caption">
Figure 4.10: Confusion matrix for the QDA model on the test set.
</p>
</div>
</center>
<p>The test error of the QDA model is 0.11.</p>
<ul>
<li><em>Question (f)</em></li>
</ul>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="classification.html#cb60-1"></a>logit_model &lt;-<span class="st"> </span><span class="kw">glm</span>(mpg01 <span class="op">~</span><span class="st"> </span>cylinders <span class="op">+</span><span class="st"> </span>displacement <span class="op">+</span><span class="st"> </span>horsepower <span class="op">+</span><span class="st"> </span>weight, <span class="dt">data =</span> train, <span class="dt">family =</span> <span class="st">&#39;binomial&#39;</span>)</span>
<span id="cb60-2"><a href="classification.html#cb60-2"></a>logit_prob &lt;-<span class="st"> </span><span class="kw">predict</span>(logit_model, <span class="dt">newdata =</span> test, <span class="dt">type =</span> <span class="st">&#39;response&#39;</span>)</span>
<span id="cb60-3"><a href="classification.html#cb60-3"></a>logit_pred &lt;-<span class="st"> </span><span class="kw">if_else</span>(logit_prob <span class="op">&gt;</span><span class="st"> </span><span class="fl">.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span></code></pre></div>
<center>
<div class="figure" style="text-align: center"><span id="fig:ex11f2"></span>
<img src="03-classification_files/figure-html/ex11f2-1.png" alt="Confusion matrix for the logistic model on the test set." width="192" />
<p class="caption">
Figure 4.11: Confusion matrix for the logistic model on the test set.
</p>
</div>
</center>
<p>The test error of the logistic model is 0.13.</p>
<ul>
<li><em>Question (g)</em></li>
</ul>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="classification.html#cb61-1"></a><span class="kw">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb61-2"><a href="classification.html#cb61-2"></a>errors_rate &lt;-<span class="st"> </span><span class="kw">c</span>()</span>
<span id="cb61-3"><a href="classification.html#cb61-3"></a>k &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">100</span>, <span class="dt">by =</span> <span class="dv">1</span>)</span>
<span id="cb61-4"><a href="classification.html#cb61-4"></a><span class="cf">for</span>(i <span class="cf">in</span> k){</span>
<span id="cb61-5"><a href="classification.html#cb61-5"></a>  knn_model &lt;-<span class="st"> </span><span class="kw">knn</span>(train[, <span class="kw">c</span>(<span class="st">&#39;cylinders&#39;</span>, <span class="st">&#39;displacement&#39;</span>, <span class="st">&#39;horsepower&#39;</span>, <span class="st">&#39;weight&#39;</span>)], </span>
<span id="cb61-6"><a href="classification.html#cb61-6"></a>                   test[, <span class="kw">c</span>(<span class="st">&#39;cylinders&#39;</span>, <span class="st">&#39;displacement&#39;</span>, <span class="st">&#39;horsepower&#39;</span>, <span class="st">&#39;weight&#39;</span>)], </span>
<span id="cb61-7"><a href="classification.html#cb61-7"></a>                   train<span class="op">$</span>mpg01, <span class="dt">k =</span> i)</span>
<span id="cb61-8"><a href="classification.html#cb61-8"></a>  errors_rate &lt;-<span class="st"> </span><span class="kw">c</span>(errors_rate, <span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(knn_model <span class="op">==</span><span class="st"> </span>test<span class="op">$</span>mpg01))</span>
<span id="cb61-9"><a href="classification.html#cb61-9"></a>}</span>
<span id="cb61-10"><a href="classification.html#cb61-10"></a>df &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">k =</span> <span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">100</span>, <span class="dt">by =</span> <span class="dv">1</span>), errors_rate)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ex11g2"></span>
<img src="03-classification_files/figure-html/ex11g2-1.png" alt="Evolution of percentage of incorrect predictions compared to $K$." width="960" />
<p class="caption">
Figure 4.12: Evolution of percentage of incorrect predictions compared to <span class="math inline">\(K\)</span>.
</p>
</div>
<p>The <span class="math inline">\(K\)</span> which give the best results for the <span class="math inline">\(K\)</span>-NN model is <span class="math inline">\(K = 3\)</span>.</p>
</div>
<div id="exercise-12.-1" class="section level3" number="4.2.3">
<h3><span class="header-section-number">4.2.3</span> Exercise 12.</h3>
<p>Consider to look <a href="http://yahwes.github.io/ISLR/exercises/ch04soln.html#ex12">here</a>.</p>
</div>
<div id="exercise-13.-1" class="section level3" number="4.2.4">
<h3><span class="header-section-number">4.2.4</span> Exercise 13.</h3>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="classification.html#cb62-1"></a>boston &lt;-<span class="st"> </span><span class="kw">as_tibble</span>(Boston)</span></code></pre></div>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="classification.html#cb63-1"></a>boston &lt;-<span class="st"> </span>boston <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb63-2"><a href="classification.html#cb63-2"></a><span class="st">            </span><span class="kw">mutate</span>(<span class="dt">crim01 =</span> <span class="kw">if_else</span>(crim <span class="op">&gt;</span><span class="st"> </span><span class="kw">median</span>(crim), <span class="dv">1</span>, <span class="dv">0</span>)) <span class="op">%&gt;%</span></span>
<span id="cb63-3"><a href="classification.html#cb63-3"></a><span class="st">            </span><span class="kw">mutate</span>(<span class="dt">crim01 =</span> <span class="kw">as_factor</span>(crim01)) <span class="op">%&gt;%</span></span>
<span id="cb63-4"><a href="classification.html#cb63-4"></a><span class="st">          </span><span class="kw">select</span>(<span class="op">-</span><span class="kw">c</span>(crim))</span></code></pre></div>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="classification.html#cb64-1"></a><span class="kw">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb64-2"><a href="classification.html#cb64-2"></a>idx &lt;-<span class="st"> </span>boston<span class="op">$</span>crim01 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">createDataPartition</span>(<span class="dt">p =</span> <span class="fl">0.7</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>, <span class="dt">times =</span> <span class="dv">1</span>)</span>
<span id="cb64-3"><a href="classification.html#cb64-3"></a>train &lt;-<span class="st"> </span>boston[idx, ]</span>
<span id="cb64-4"><a href="classification.html#cb64-4"></a>test &lt;-<span class="st"> </span>boston[<span class="op">-</span>idx, ]</span></code></pre></div>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="classification.html#cb65-1"></a>lda_model &lt;-<span class="st"> </span><span class="kw">lda</span>(crim01 <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> train)</span>
<span id="cb65-2"><a href="classification.html#cb65-2"></a>lda_prob &lt;-<span class="st"> </span><span class="kw">predict</span>(lda_model, test)<span class="op">$</span>posterior[, <span class="st">&#39;1&#39;</span>]</span>
<span id="cb65-3"><a href="classification.html#cb65-3"></a>lda_pred &lt;-<span class="st"> </span><span class="kw">if_else</span>(lda_prob <span class="op">&gt;</span><span class="st"> </span><span class="fl">.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span></code></pre></div>
<center>
<div class="figure" style="text-align: center"><span id="fig:ex13d"></span>
<img src="03-classification_files/figure-html/ex13d-1.png" alt="Confusion matrix for the LDA model on the test set." width="192" />
<p class="caption">
Figure 3.7: Confusion matrix for the LDA model on the test set.
</p>
</div>
</center>
<p>The test error of the LDA model is 0.13.</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="classification.html#cb66-1"></a>qda_model &lt;-<span class="st"> </span><span class="kw">qda</span>(crim01 <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> train)</span>
<span id="cb66-2"><a href="classification.html#cb66-2"></a>qda_prob &lt;-<span class="st"> </span><span class="kw">predict</span>(qda_model, test)<span class="op">$</span>posterior[, <span class="st">&#39;1&#39;</span>]</span>
<span id="cb66-3"><a href="classification.html#cb66-3"></a>qda_pred &lt;-<span class="st"> </span><span class="kw">if_else</span>(qda_prob <span class="op">&gt;</span><span class="st"> </span><span class="fl">.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span></code></pre></div>
<center>
<div class="figure" style="text-align: center"><span id="fig:ex13f"></span>
<img src="03-classification_files/figure-html/ex13f-1.png" alt="Confusion matrix for the QDA model on the test set." width="192" />
<p class="caption">
Figure 3.8: Confusion matrix for the QDA model on the test set.
</p>
</div>
</center>
<p>The test error of the QDA model is 0.12.</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="classification.html#cb67-1"></a>logit_model &lt;-<span class="st"> </span><span class="kw">glm</span>(crim01 <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> train, <span class="dt">family =</span> <span class="st">&#39;binomial&#39;</span>)</span>
<span id="cb67-2"><a href="classification.html#cb67-2"></a>logit_prob &lt;-<span class="st"> </span><span class="kw">predict</span>(logit_model, <span class="dt">newdata =</span> test, <span class="dt">type =</span> <span class="st">&#39;response&#39;</span>)</span>
<span id="cb67-3"><a href="classification.html#cb67-3"></a>logit_pred &lt;-<span class="st"> </span><span class="kw">if_else</span>(logit_prob <span class="op">&gt;</span><span class="st"> </span><span class="fl">.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span></code></pre></div>
<center>
<div class="figure" style="text-align: center"><span id="fig:ex13h"></span>
<img src="03-classification_files/figure-html/ex13h-1.png" alt="Confusion matrix for the logistic model on the test set." width="192" />
<p class="caption">
Figure 4.13: Confusion matrix for the logistic model on the test set.
</p>
</div>
</center>
<p>The test error of the logistic model is 0.09.</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="classification.html#cb68-1"></a><span class="kw">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb68-2"><a href="classification.html#cb68-2"></a>errors_rate &lt;-<span class="st"> </span><span class="kw">c</span>()</span>
<span id="cb68-3"><a href="classification.html#cb68-3"></a>k &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">100</span>, <span class="dt">by =</span> <span class="dv">1</span>)</span>
<span id="cb68-4"><a href="classification.html#cb68-4"></a><span class="cf">for</span>(i <span class="cf">in</span> k){</span>
<span id="cb68-5"><a href="classification.html#cb68-5"></a>  knn_model &lt;-<span class="st"> </span><span class="kw">knn</span>(<span class="kw">select</span>(train, <span class="op">-</span><span class="kw">c</span>(<span class="st">&#39;crim01&#39;</span>)), </span>
<span id="cb68-6"><a href="classification.html#cb68-6"></a>                   <span class="kw">select</span>(test, <span class="op">-</span><span class="kw">c</span>(<span class="st">&#39;crim01&#39;</span>)), </span>
<span id="cb68-7"><a href="classification.html#cb68-7"></a>                   train<span class="op">$</span>crim01, <span class="dt">k =</span> i)</span>
<span id="cb68-8"><a href="classification.html#cb68-8"></a>  errors_rate &lt;-<span class="st"> </span><span class="kw">c</span>(errors_rate, <span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(knn_model <span class="op">==</span><span class="st"> </span>test<span class="op">$</span>crim01))</span>
<span id="cb68-9"><a href="classification.html#cb68-9"></a>}</span>
<span id="cb68-10"><a href="classification.html#cb68-10"></a>df &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">k =</span> <span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">100</span>, <span class="dt">by =</span> <span class="dv">1</span>), errors_rate)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ex13j"></span>
<img src="03-classification_files/figure-html/ex13j-1.png" alt="Evolution of percentage of incorrect predictions compared to $K$." width="960" />
<p class="caption">
Figure 3.10: Evolution of percentage of incorrect predictions compared to <span class="math inline">\(K\)</span>.
</p>
</div>
<p>The <span class="math inline">\(K\)</span> which give the best results for the <span class="math inline">\(K\)</span>-NN model is <span class="math inline">\(K = 4\)</span> or <span class="math inline">\(K = 5\)</span>.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="linear-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="resampling-methods.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
